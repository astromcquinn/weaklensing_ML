{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed531a95",
      "metadata": {
        "id": "ed531a95"
      },
      "source": [
        "#Implements encoder/decoder for weak lensing outputs\n",
        "\n",
        "The major idea is to see if I can compress the data in the snapshot files.\n",
        "The result is that the compression of many different algorithms based on CNNs (of different depths) is not so much different than averaging neighboring cells.  This in retrospect is not so surprising as there are differences on the cell scale in the maps that make compression challenging."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set configurations for COLAB if running there"
      ],
      "metadata": {
        "id": "zQpe_fjWxGwO"
      },
      "id": "zQpe_fjWxGwO"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "use_COLAB = 1\n",
        "\n",
        "if use_COLAB == 1:\n",
        "  #mount drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  WORK_AREA = '/content/gdrive/My Drive/weaklensing_ML/' #columbialensing/\n",
        "  os.chdir(WORK_AREA)\n",
        "\n",
        "  #get GPU info\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEtElnI8fDj1",
        "outputId": "2feebb05-e59b-4c06-94d7-2338f0295d09"
      },
      "id": "KEtElnI8fDj1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## extract tarfiles if necessary and set specs for run\n",
        "\n"
      ],
      "metadata": {
        "id": "MSxBOjESwy_q"
      },
      "id": "MSxBOjESwy_q"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4a5315a",
      "metadata": {
        "id": "a4a5315a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tarfile\n",
        "import os\n",
        "import shutil\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "\n",
        "# Specify the directory containing the .tar files\n",
        "directory_path = './columbialensing/'\n",
        "\n",
        "\n",
        "max_cosmologies = -1 #for testing.  Set to -1 to use everything.\n",
        "\n",
        "number_batches = 10\n",
        "#validation_split = 0.4  # use this fraction of the data for validation\n",
        "normalize_by_RMS = False #set to one if you want to renormalize by RMS\n",
        "\n",
        "\n",
        "\n",
        "# image_size\n",
        "image_size = 1024 #really makes sense to use the 1024s\n",
        "sub_image_size = 64 #needs to divide image size\n",
        "number_subimages_across =image_size//sub_image_size\n",
        "\n",
        "\n",
        "number_fits_files = 512\n",
        "suffix = f\"_{image_size}\"\n",
        "extract_tarfiles = False  #if I need to extract tarfiles\n",
        "\n",
        "run_suffix = rf\"im{image_size}\"\n",
        "\n",
        "#extracts only if indicated (could make this more elegant by checking to see if they exist)\n",
        "if extract_tarfiles:\n",
        "    # Use a regular expression to match .tar files with the desired suffix\n",
        "    pattern = re.compile(rf\"{suffix}.tar$\")\n",
        "\n",
        "    # List all matching .tar files in the directory\n",
        "    all_tar_files = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "\n",
        "    # Extract the tar archive\n",
        "    for tar_file in all_tar_files:\n",
        "        #print(tar_file)\n",
        "        tar_file_path = os.path.join(directory_path, tar_file)\n",
        "        with tarfile.open(tar_file_path, 'r') as archive:\n",
        "            archive.extractall(path=directory_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0619681f",
      "metadata": {
        "id": "0619681f"
      },
      "source": [
        "# Read into memory the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "48a05090",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48a05090",
        "outputId": "e9789e97-ff22-4563-a43e-c98e38e1f84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading in Om0.268_si0.801\n",
            "RMS=0.016497720032930374\n"
          ]
        }
      ],
      "source": [
        "def get_labels_for_file(dir_name):\n",
        "    \"\"\"\n",
        "    Extracts labels from the tar file name.\n",
        "    For the file \"Om0.183_si0.958_256.tar\", the labels will be [0.183, 0.958].\n",
        "\n",
        "    Args:\n",
        "    - tar_file_name (str): Name of the tar file.\n",
        "\n",
        "    Returns:\n",
        "    - list: List containing the two labels extracted from the filename.\n",
        "    \"\"\"\n",
        "    # Split the filename on underscores\n",
        "    parts = dir_name.split('_')\n",
        "\n",
        "    # Extract the numeric values for 'Om' and 'si'\n",
        "    om_label = float(parts[0][2:])\n",
        "    si_label = float(parts[1][2:])\n",
        "\n",
        "    return [om_label, si_label]\n",
        "\n",
        "\n",
        "#now loop through all files in the\n",
        "pattern = re.compile(rf\"{suffix}$\")\n",
        "#all_directories = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "all_directories = [\"Om0.268_si0.801\"] # \"Om0.283_si0.805_256\"\n",
        "num_cosmologies = len(all_directories)\n",
        "\n",
        "random.shuffle(all_directories) #this makes it so that there is no particular order for the directories\n",
        "#print(all_directories)\n",
        "\n",
        "#tensor of labels; there are two labels for each\n",
        "numsubimages = number_subimages_across**2\n",
        "number_images = number_fits_files*numsubimages\n",
        "#cosmology_labels = np.empty((len(all_directories), number_images, 2), dtype=np.float16)\n",
        "\n",
        "RMS =0 #first time set to zero\n",
        "data_array = np.empty((num_cosmologies, number_images, sub_image_size, sub_image_size), dtype=np.float16)\n",
        "for idy, dir_name in enumerate(all_directories):\n",
        "    if max_cosmologies>0 and idy >= max_cosmologies:\n",
        "        break\n",
        "\n",
        "    #if idy%10 ==0:\n",
        "    print(\"reading in\", dir_name)\n",
        "    dir_path = os.path.join(directory_path, dir_name)\n",
        "\n",
        "    all_files = os.listdir(dir_path)\n",
        "    fits_files = [f for f in all_files if f.endswith('.fits')]\n",
        "\n",
        "\n",
        "\n",
        "    for idx, file in enumerate(fits_files):\n",
        "        with fits.open(os.path.join(dir_path, file)) as hdul:\n",
        "\n",
        "            original_data = hdul[0].data\n",
        "\n",
        "            if RMS == 0: #get RMS to divide by for first file to normalize everything\n",
        "                RMS = np.sqrt(np.var(hdul[0].data))\n",
        "                print(f\"RMS={RMS}\")\n",
        "\n",
        "            ##get rid of NANs, which affects a few files\n",
        "            #if np.isnan(original_data).any():\n",
        "            #    continue\n",
        "            #I've cleaned this out already\n",
        "            for i in range(number_subimages_across):\n",
        "                for j in range(number_subimages_across):\n",
        "                    data_array[idy][numsubimages*idx+ number_subimages_across*i+j] = original_data[sub_image_size*i:sub_image_size*(i+1),\\\n",
        "                                                                  sub_image_size*j:sub_image_size*(j+1)]\n",
        "\n",
        "    #since all fits files in one directory have the same label\n",
        "    cosmology = get_labels_for_file(dir_name)\n",
        "    #cosmology_labels[idy] = np.array([cosmology for i in range(number_fits_files)])\n",
        "\n",
        "\n",
        "    #flatten data_array[idy][numsubimages*idx+ number_subimages_across*i+j]\n",
        "WL_tensor = tf.convert_to_tensor(data_array)\n",
        "\n",
        "WL_tensor = tf.reshape(WL_tensor, (-1, WL_tensor.shape[2], WL_tensor.shape[3]));\n",
        "\n",
        "WL_tensor = WL_tensor[..., np.newaxis]  # Add channel dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621149d6",
      "metadata": {
        "id": "621149d6"
      },
      "source": [
        "# create decoder-encoder CNN with minimal number of layers, but final dense layer.  \n",
        "\n",
        "  Here n sets the compression with the size compressed by the factor 4^n.  The result is n+1 layers, and most experiments I've run to test are n=2, or a compression by a factor of 16.\n",
        "\n",
        "  The n CNN layers have number_channels channels, where I've experimented with 64 and 256\n",
        "\n",
        "If load_saved= 1, it loads a trained version of this decoder-encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "828293a3",
      "metadata": {
        "id": "828293a3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=2 #number of layers (needs to be >2)\n",
        "number_channels = 64\n",
        "dropout_rate = 0\n",
        "\n",
        "L1weight = 0 #1e-8\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_simple_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_string, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "              kernel_regularizer=regularizer))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_simple_decoder(encoded_length, original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    model.add(layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string,\\\n",
        "              kernel_regularizer=regularizer))\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_string, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "load_saved = 1\n",
        "\n",
        "model_name = f'simple_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    simple_encoder = load_model(model_name)\n",
        "    simple_decoder = load_model(f'simple_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  simple_encoder = create_simple_encoder(original_shape , n)\n",
        "  simple_decoder = create_simple_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "simple_autoencoder = models.Sequential([simple_encoder, simple_decoder])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sets a learning rate scheduler and compiles the model\n",
        "\n",
        "I've experimented with larger learning rates than 0.001, finding that five times this is too high as loss is very non-monatonic"
      ],
      "metadata": {
        "id": "_THCdXrHyYA-"
      },
      "id": "_THCdXrHyYA-"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff71209a",
      "metadata": {
        "id": "ff71209a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea000fc8-862f-49ba-e217-3d640bdd1020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4194560   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,213,632\n",
            "Trainable params: 4,213,504\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 16384)             4210688   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 32, 32, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,266,369\n",
            "Trainable params: 4,266,241\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "# Set the learning rate (I find that .005 is too large)\n",
        "learning_rate = 0.001\n",
        "\n",
        "#I was curious about how much of the loss owed to regularization, so this allows me to check at end of each batch (but was generating a warning in first batch)\n",
        "class RegularizationLossMonitor(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        regularization_loss = sum(self.model.losses)\n",
        "        total_loss = logs['loss']\n",
        "        data_loss = total_loss - regularization_loss\n",
        "        print(f'\\n Regularization loss: {regularization_loss:.4f}',)\n",
        "        print(f'Data loss: {data_loss:.4f}',)\n",
        "        print(f'Total loss: {total_loss:.4f}')\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.0001)\n",
        "\n",
        "simple_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "\n",
        "simple_encoder.summary() #summary of encoder\n",
        "simple_decoder.summary() #summary of decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "Ex2CN7yS1nje"
      },
      "id": "Ex2CN7yS1nje"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec6a8f7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6a8f7c",
        "outputId": "367313d7-4419-4e2c-b032-82528b7c273b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 313s 607ms/step - loss: 0.0075 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 308s 601ms/step - loss: 0.0054 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 292s 570ms/step - loss: 0.0048 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 291s 569ms/step - loss: 0.0045 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 291s 569ms/step - loss: 0.0043 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 293s 572ms/step - loss: 0.0042 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 292s 570ms/step - loss: 0.0041 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 295s 576ms/step - loss: 0.0040 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 296s 578ms/step - loss: 0.0040 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 294s 574ms/step - loss: 0.0040 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 299s 584ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 293s 572ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 294s 573ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 294s 574ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 293s 573ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 294s 574ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 293s 573ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 297s 581ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 296s 579ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 293s 573ms/step - loss: 0.0038 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ce52f2b7b80>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "simple_autoencoder.fit(WL_tensor, WL_tensor,\n",
        "                epochs=20,\n",
        "                batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_encoder.save(f'simple_encoder_{save_string}.keras')\n",
        "simple_decoder.save(f'simple_decoder_{save_string}.keras')"
      ],
      "metadata": {
        "id": "lZbiSXCQZ5y1",
        "outputId": "3090b94d-24c2-492c-96aa-89c66fcd8f6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lZbiSXCQZ5y1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder-decoder 2:  \n",
        "\n",
        "This takes out the dense layers and replaces it with 1x1 convolution layer.  This makes a pure CNN encoder-decoder and the output now is in terms of pixels and channels rather than one vector.  This felt more physically motivated.  Now n=4 and 16 channels is the same compression as n=2 previously."
      ],
      "metadata": {
        "id": "7rHxc33vp9W3"
      },
      "id": "7rHxc33vp9W3"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=4 #number of layers (needs to be >2)\n",
        "number_channels = 256 #these are intermediat channels\n",
        "number_final_channels = 16\n",
        "dropout_rate = 0\n",
        "\n",
        "L1weight = 1e-8\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_nfc{number_final_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_CNN_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=None, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "\n",
        "    model.add(layers.Conv2D(number_final_channels, (1, 1), activation=None, padding='same',\\\n",
        "          kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "    #model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "    #          kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_CNN_decoder(original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer( (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_final_channels)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=None, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "load_saved = 1\n",
        "\n",
        "model_name = f'CNN_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    CNN_encoder = load_model(model_name)\n",
        "    CNN_decoder = load_model(f'CNN_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  CNN_encoder = create_CNN_encoder(original_shape, n)\n",
        "  CNN_decoder = create_CNN_decoder(original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "CNN_autoencoder = models.Sequential([CNN_encoder, CNN_decoder])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658b8wytptj2",
        "outputId": "5d248fd4-583a-47e6-eb4e-d808baf23689"
      },
      "id": "658b8wytptj2",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path does not exist to CNN_encoder_n4_nc256_nfc16_d0_logL1w-08.keras.  Creating model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_encoder.summary()\n",
        "CNN_decoder.summary()\n",
        "\n",
        "learning_rate = .001\n",
        "\n",
        "CNN_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiALX9LEp7FV",
        "outputId": "7b4f199e-2fcb-47fd-d133-7f1ebaae40c1"
      },
      "id": "PiALX9LEp7FV",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 128)       1280      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 16)          4112      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4, 4, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,484,368\n",
            "Trainable params: 1,482,544\n",
            "Non-trainable params: 1,824\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_transpose_2 (Conv2DT  (None, 4, 4, 256)        4352      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 4, 4, 256)        590080    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 8, 8, 256)        590080    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 16, 16, 256)      590080    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16, 16, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " up_sampling2d_4 (UpSampling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 32, 32, 128)      295040    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " up_sampling2d_5 (UpSampling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 1)         129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,074,369\n",
            "Trainable params: 2,072,065\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_autoencoder.fit(WL_tensor, WL_tensor,\n",
        "                epochs=20,\n",
        "                batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Y0geI0hW3WnE",
        "outputId": "1fdc993a-064e-4f79-d08f-91c01cf75655"
      },
      "id": "Y0geI0hW3WnE",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            " 10/512 [..............................] - ETA: 40:41 - loss: 0.4789"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-706d49f78c90>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m CNN_autoencoder.fit(WL_tensor, WL_tensor,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_encoder.save(f'CNN_encoder_{save_string}.keras')\n",
        "CNN_decoder.save(f'CNN_decoder_{save_string}.keras')"
      ],
      "metadata": {
        "id": "OueELMBd7HuO"
      },
      "id": "OueELMBd7HuO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder Decoder 3 (residual connections)\n",
        "\n",
        "This now is the same CNN as our first but with residual connections"
      ],
      "metadata": {
        "id": "ifU_ceKxiGtH"
      },
      "id": "ifU_ceKxiGtH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbAkbrpXiMrT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "number_channels = 64\n",
        "dropout_rate = 0\n",
        "\n",
        "L1weight = 1e-8\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "\n",
        "def create_encoder_residconnect(input_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Initial Convolutional Layer\n",
        "    x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Additional Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Flatten and Dense Layer\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "def create_decoder_residconnect(encoded_length, original_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=(encoded_length,))\n",
        "    x = inputs\n",
        "\n",
        "    # Dense layer\n",
        "    x = layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    x = layers.Reshape((original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "\n",
        "    # Upsampling Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Final Conv2DTranspose to get back to original shape\n",
        "    x = layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "load_saved = 1\n",
        "model_name = f'encoder_residconnect_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    encoder_residconnect= load_model(f'encoder_residconnect_{save_string}.keras')\n",
        "    decoder_residconnect = load_model(f'decoder_residconnect_{save_string}.keras')\n",
        "\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  encoder_residconnect = create_encoder_residconnect(original_shape , n)\n",
        "  decoder_residconnect = create_decoder_residconnect(encoded_length,original_shape, n)\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "autoencoder_residconnect = models.Sequential([encoder_residconnect, decoder_residconnect])\n",
        "\n",
        "encoder_residconnect.summary()\n",
        "decoder_residconnect.summary()"
      ],
      "id": "KbAkbrpXiMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "autoencoder_residconnect = models.Sequential([encoder_residconnect, decoder_residconnect])\n",
        "#autoencoder_residconnect.summary()\n",
        "\n",
        "autoencoder_residconnect.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")\n",
        "\n",
        "autoencoder_residconnect.fit(WL_tensor, WL_tensor,\n",
        "                epochs=40,\n",
        "                batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()"
      ],
      "metadata": {
        "id": "zJb9DKNqizkS"
      },
      "id": "zJb9DKNqizkS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_residconnect.save(f'encoder_residconnect_{save_string}.keras')\n",
        "decoder_residconnect.save(f'decoder_residconnect_{save_string}.keras')"
      ],
      "metadata": {
        "id": "qTDG33XFy2Ec"
      },
      "id": "qTDG33XFy2Ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "95cc9323",
      "metadata": {
        "id": "95cc9323"
      },
      "source": [
        "## Encoder-decoder 4: most complex model\n",
        "\n",
        "I've added 2*(n-1) additional layers, half 1x1 convolutions and half 3x3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82c7819",
      "metadata": {
        "id": "b82c7819"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "number_channels = 64\n",
        "\n",
        "act_func = LeakyReLU(alpha=0.1)\n",
        "\n",
        "L1weight = 0 #1e-8\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "\n",
        "def create_encoder(input_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_decoder(encoded_length, original_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    model.add(layers.Dense(units=np.prod(encoded_length*64), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), 64)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "load_saved = 1\n",
        "model_name = f'encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    encoder= load_model(f'encoder_{save_string}.keras')\n",
        "    decoder = load_model(f'decoder_{save_string}.keras')\n",
        "else:\n",
        "    if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model...\")\n",
        "    # Combine the encoder and decoder to create the autoencoder\n",
        "    encoder = create_encoder(original_shape , n)\n",
        "    decoder = create_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "autoencoder = models.Sequential([encoder, decoder])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de30dd6",
      "metadata": {
        "id": "0de30dd6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an Adam optimizer with the desired learning rate\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "def fractional_difference_loss(y_true, y_pred):\n",
        "    # Avoid division by zero\n",
        "    epsilon = .01 # A small, non-zero number to prevent division by zero\n",
        "    # Calculate the fractional difference\n",
        "    loss = K.mean(K.abs((y_pred - y_true) / (K.abs(y_true) + epsilon)), axis=-1)\n",
        "    return loss\n",
        "\n",
        "def fractional_square_loss(y_true, y_pred):\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-2 # A small, non-zero number to prevent division by zero\n",
        "    # Calculate the fractional difference\n",
        "    loss = K.square((y_pred - y_true) / (K.abs(y_true) + epsilon))\n",
        "    return loss\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0659942d",
      "metadata": {
        "id": "0659942d"
      },
      "source": [
        "# train complex CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da431d7",
      "metadata": {
        "id": "7da431d7"
      },
      "outputs": [],
      "source": [
        "print(WL_tensor.shape)\n",
        "\n",
        "#encoded = encoder(WL_tensor[:256, :, :, :])\n",
        "#decoder(encoded)\n",
        "\n",
        "autoencoder.fit(WL_tensor, WL_tensor,\n",
        "                epochs=40,\n",
        "                batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.save(f'encoder_{save_string}.keras')\n",
        "decoder.save(f'decoder_{save_string}.keras')"
      ],
      "metadata": {
        "id": "Mtk3WN-x80el"
      },
      "id": "Mtk3WN-x80el",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This shows images from the various encoders/decoders\n",
        "\n",
        "change number_dcoders to compare more decoders, if they are loaded\n"
      ],
      "metadata": {
        "id": "FndU2Dzi3GSJ"
      },
      "id": "FndU2Dzi3GSJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca90b78c",
      "metadata": {
        "id": "ca90b78c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming WL_tensor is a 4D tensor with shape (num_images, height, width, channels)\n",
        "# and sub_image_size is the size of the second and third dimensions (height and width).\n",
        "num_images = 5\n",
        "sub_image_size = WL_tensor.shape[1]  # Assuming height and width are the same\n",
        "\n",
        "number_decoders = 1\n",
        "\n",
        "# Get the outputs from the decoder\n",
        "decoded_images1 = simple_decoder(simple_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "if number_decoders >= 2:\n",
        "  decoded_images2 = CNN_decoder(CNN_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=3:\n",
        "    decoded_images3 = decoder_residconnect(encoder_residconnect(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=4:\n",
        "    decoded_images4 = decoder(encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "# Function to display images\n",
        "def display_side_by_side(index):\n",
        "    if index < 0 or index >= num_images:\n",
        "        raise ValueError(\"Index out of bounds\")\n",
        "\n",
        "    # Select the specific input and output images\n",
        "    input_image = WL_tensor[index, :, :, 0]  # Assuming grayscale, channel dimension is 0\n",
        "    output_image1 = decoded_images1[index, :, :, 0]  # Also assuming grayscale\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, axes = plt.subplots(1, number_decoders+1, figsize=(4*number_decoders, 10))\n",
        "\n",
        "    # Display the input image in the first subplot\n",
        "    axes[0].imshow(input_image, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "    axes[0].set_title(f'Input Image {index}')\n",
        "    axes[0].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the output image in the second subplot\n",
        "    axes[1].imshow(output_image1, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "    axes[1].set_title(f'Decoded Image {index}')\n",
        "    axes[1].axis('off')  # Hide the axis\n",
        "\n",
        "    if number_decoders >=2:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image2 = decoded_images2[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[2].imshow(output_image2, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[2].set_title(f'Decoded 2 Image {index}')\n",
        "      axes[2].axis('off')  # Hide the axis\n",
        "\n",
        "    if number_decoders >=3:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image3 = decoded_images3[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[3].imshow(output_image3, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[3].set_title(f'Decoded 3 Image {index}')\n",
        "      axes[3].axis('off')  # Hide the axis\n",
        "\n",
        "\n",
        "    if number_decoders >=4:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image4 = decoded_images4[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[3].imshow(output_image4, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[3].set_title(f'Decoded 4 Image {index}')\n",
        "      axes[3].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the images\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage for the first image\n",
        "display_side_by_side(0)  # You can loop or call this function for other indices as well\n",
        "display_side_by_side(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e8d6bc",
      "metadata": {
        "id": "97e8d6bc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}