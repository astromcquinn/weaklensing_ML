{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed531a95",
      "metadata": {
        "id": "ed531a95"
      },
      "source": [
        "#Implements encoder/decoder for weak lensing outputs\n",
        "\n",
        "The major idea is to see if I can compress the data in the snapshot files.\n",
        "The result is that the compression of many different algorithms based on CNNs (of different depths) is not so much different than averaging neighboring cells (as shown at the end).  This in retrospect is not so surprising as there are differences on the cell scale in the maps that make compression challenging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zQpe_fjWxGwO",
      "metadata": {
        "id": "zQpe_fjWxGwO"
      },
      "source": [
        "Set configurations for google COLAB if running there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KEtElnI8fDj1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEtElnI8fDj1",
        "outputId": "a85b282f-b9e4-4f0a-a93a-7d9cc6d4932d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "use_COLAB = 1 #1 is for on colab, and 2 is for on local machine but using colab\n",
        "\n",
        "if use_COLAB >= 1:\n",
        "  if use_COLAB == 2: # for running in VS CODE\n",
        "      from colabcode import ColabCode\n",
        "      ColabCode(port=10000)\n",
        "  #mount drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  WORK_AREA = '/content/gdrive/My Drive/weaklensing_ML/' #columbialensing/\n",
        "  os.chdir(WORK_AREA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MSxBOjESwy_q",
      "metadata": {
        "id": "MSxBOjESwy_q"
      },
      "source": [
        "\n",
        "## extract tarfiles if necessary and set specs for run\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a5315a",
      "metadata": {
        "id": "a4a5315a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tarfile\n",
        "import os\n",
        "import shutil\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "#whether we are training or loading saved\n",
        "train = True\n",
        "load_saved = 0\n",
        "\n",
        "#regularization parameters:\n",
        "## generalization seems great on cosmological data and so generally I run with these off\n",
        "L1weight = 0 #1e-8\n",
        "dropout_rate = 0\n",
        "\n",
        "# Specify the directory containing the .tar files\n",
        "directory_path = './columbialensing/'\n",
        "\n",
        "number_batches = 10\n",
        "normalize_by_RMS = False #set to one if you want to renormalize by RMS\n",
        "\n",
        "# image_size\n",
        "image_size = 1024\n",
        "sub_image_size = 64 #needs to divide image into these units; must divide evenly image_size\n",
        "                    #division is using that it is unlikely there are learnable correlations\n",
        "                    #that allow one to compress the data on large scales in the images\n",
        "                    #dividing images gives more samples to learn correlations\n",
        "\n",
        "\n",
        "\n",
        "number_subimages_across =image_size//sub_image_size\n",
        "\n",
        "\n",
        "number_fits_files = 512\n",
        "suffix = f\"_{image_size}\"\n",
        "extract_tarfiles = False  #if I need to extract tarfiles\n",
        "\n",
        "run_suffix = rf\"im{image_size}\"\n",
        "\n",
        "#extracts only if indicated (could make this more elegant by checking to see if they exist)\n",
        "if extract_tarfiles:\n",
        "    # Use a regular expression to match .tar files with the desired suffix\n",
        "    pattern = re.compile(rf\"{suffix}.tar$\")\n",
        "\n",
        "    # List all matching .tar files in the directory\n",
        "    all_tar_files = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "\n",
        "    # Extract the tar archive\n",
        "    for tar_file in all_tar_files:\n",
        "        #print(tar_file)\n",
        "        tar_file_path = os.path.join(directory_path, tar_file)\n",
        "        with tarfile.open(tar_file_path, 'r') as archive:\n",
        "            archive.extractall(path=directory_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hikn1ojDWiGH",
      "metadata": {
        "id": "hikn1ojDWiGH"
      },
      "source": [
        "# training schedule, import optimizer, and custom loss functions\n",
        "\n",
        "I dont' necessarily use these, but used them to understand network optimization choices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3i4uiA3rWg_n",
      "metadata": {
        "id": "3i4uiA3rWg_n"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "#I was curious about how much of the loss owed to regularization, so this allows me to check at end of each batch (but was generating a warning in first batch)\n",
        "class RegularizationLossMonitor(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        regularization_loss = sum(self.model.losses)\n",
        "        total_loss = logs['loss']\n",
        "        data_loss = total_loss - regularization_loss\n",
        "        print(f'\\n Regularization loss: {regularization_loss:.4f}',)\n",
        "        print(f'Data loss: {data_loss:.4f}',)\n",
        "        print(f'Total loss: {total_loss:.4f}')\n",
        "\n",
        "#custom loss that compares fractional difference:  this metric makes sense\n",
        "#because we want images that are close to each other everywhere.\n",
        "#might not be ideal for optimization\n",
        "def fractional_difference_loss(y_true, y_pred):\n",
        "    epsilon = .01 # A small, non-zero number to prevent division by zero\n",
        "    loss = K.mean(K.abs((y_pred - y_true) / (K.abs(y_true) + epsilon)), axis=-1)\n",
        "    return loss\n",
        "\n",
        "#custom loss that quare fo the fractional difference\n",
        "def fractional_square_loss(y_true, y_pred):\n",
        "    epsilon = 1e-2 # A small, non-zero number to prevent division by zero\n",
        "    loss = K.square((y_pred - y_true) / (K.abs(y_true) + epsilon))\n",
        "    return loss\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0619681f",
      "metadata": {
        "id": "0619681f"
      },
      "source": [
        "# Read into memory the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a05090",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48a05090",
        "outputId": "9137141a-8ed0-4e1e-c7ef-e19b79ff25db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading in Om0.268_si0.801\n",
            "RMS=0.016497720032930374\n"
          ]
        }
      ],
      "source": [
        "#import wl_auxiliary\n",
        "\n",
        "def get_labels_for_file(dir_name):\n",
        "    \"\"\"\n",
        "    Extracts labels from the tar file name.\n",
        "    For the file \"Om0.183_si0.958_256.tar\", the labels will be [0.183, 0.958].\n",
        "\n",
        "    Args:\n",
        "    - tar_file_name (str): Name of the tar file.\n",
        "\n",
        "    Returns:\n",
        "    - list: List containing the two labels extracted from the filename.\n",
        "    \"\"\"\n",
        "    # Split the filename on underscores\n",
        "    parts = dir_name.split('_')\n",
        "\n",
        "    # Extract the numeric values for 'Om' and 'si'\n",
        "    om_label = float(parts[0][2:])\n",
        "    si_label = float(parts[1][2:])\n",
        "\n",
        "    return [om_label, si_label]\n",
        "\n",
        "#now loop through all files in the\n",
        "pattern = re.compile(rf\"{suffix}$\")\n",
        "#all_directories = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "all_directories = [\"Om0.268_si0.801\"] # \"Om0.283_si0.805_256\"\n",
        "num_cosmologies = len(all_directories)\n",
        "\n",
        "random.shuffle(all_directories) #this makes it so that there is no particular order for the directories\n",
        "#print(all_directories)\n",
        "\n",
        "#tensor of labels; there are two labels for each\n",
        "numsubimages = number_subimages_across**2\n",
        "number_images = number_fits_files*numsubimages\n",
        "#cosmology_labels = np.empty((len(all_directories), number_images, 2), dtype=np.float16)\n",
        "\n",
        "RMS =0 #first time set to zero\n",
        "data_array = np.empty((num_cosmologies, number_images, sub_image_size, sub_image_size), dtype=np.float16)\n",
        "for idy, dir_name in enumerate(all_directories):\n",
        "\n",
        "\n",
        "    #if idy%10 ==0:\n",
        "    print(\"reading in\", dir_name)\n",
        "    dir_path = os.path.join(directory_path, dir_name)\n",
        "\n",
        "    all_files = os.listdir(dir_path)\n",
        "    fits_files = [f for f in all_files if f.endswith('.fits')]\n",
        "\n",
        "\n",
        "\n",
        "    for idx, file in enumerate(fits_files):\n",
        "        with fits.open(os.path.join(dir_path, file)) as hdul:\n",
        "\n",
        "            original_data = hdul[0].data\n",
        "\n",
        "            if RMS == 0: #get RMS to divide by for first file to normalize everything\n",
        "                RMS = np.sqrt(np.var(hdul[0].data))\n",
        "                print(f\"RMS={RMS}\")\n",
        "\n",
        "            ##get rid of NANs, which affects a few files\n",
        "            #if np.isnan(original_data).any():\n",
        "            #    continue\n",
        "            #I've cleaned this out already\n",
        "            for i in range(number_subimages_across):\n",
        "                for j in range(number_subimages_across):\n",
        "                    data_array[idy][numsubimages*idx+ number_subimages_across*i+j] = original_data[sub_image_size*i:sub_image_size*(i+1),\\\n",
        "                                                                  sub_image_size*j:sub_image_size*(j+1)]/RMS\n",
        "\n",
        "    #since all fits files in one directory have the same label\n",
        "    cosmology = get_labels_for_file(dir_name)\n",
        "    #cosmology_labels[idy] = np.array([cosmology for i in range(number_fits_files)])\n",
        "\n",
        "\n",
        "    #flatten data_array[idy][numsubimages*idx+ number_subimages_across*i+j]\n",
        "WL_tensor = tf.convert_to_tensor(data_array)\n",
        "\n",
        "WL_tensor = tf.reshape(WL_tensor, (-1, WL_tensor.shape[2], WL_tensor.shape[3]));\n",
        "\n",
        "WL_tensor = WL_tensor[..., np.newaxis]  # Add channel dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621149d6",
      "metadata": {
        "id": "621149d6"
      },
      "source": [
        "# create decoder-encoder CNN with minimal number of layers, but final dense layer.  \n",
        "\n",
        "  Here n sets the compression with the size compressed by the factor 4^n.  The result is n+1 layers, and most experiments I've run to test are n=2, or a compression by a factor of 16.\n",
        "\n",
        "  The n CNN layers have number_channels channels, where I've experimented with 64 and 256\n",
        "\n",
        "If load_saved= 1, it loads a trained version of this decoder-encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828293a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "828293a3",
        "outputId": "ed500106-fd19-48e7-c1a2-f77a1628d806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading saved modelsimple_encoder_n2_nc64_d0_logL1w+00.keras\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=2 #number of layers (needs to be >2)\n",
        "number_channels = 64\n",
        "\n",
        "act_string = 'ReLU' #LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_simple_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_string, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "              kernel_regularizer=regularizer))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_simple_decoder(encoded_length, original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    model.add(layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string,\\\n",
        "              kernel_regularizer=regularizer))\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_string, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "\n",
        "model_name = f'simple_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    print(f\"loading saved model{model_name}\")\n",
        "    simple_encoder = load_model(model_name)\n",
        "    simple_decoder = load_model(f'simple_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  simple_encoder = create_simple_encoder(original_shape , n)\n",
        "  simple_decoder = create_simple_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "simple_autoencoder = models.Sequential([simple_encoder, simple_decoder])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff71209a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff71209a",
        "outputId": "14d5c9de-db2d-401a-8373-24a09c753a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4213632 (16.07 MB)\n",
            "Trainable params: 4213504 (16.07 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16384)             4210688   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 16, 16, 64)        36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSamplin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4266369 (16.27 MB)\n",
            "Trainable params: 4266241 (16.27 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "simple_encoder.summary() #summary of encoder\n",
        "simple_decoder.summary() #summary of decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ex2CN7yS1nje",
      "metadata": {
        "id": "Ex2CN7yS1nje"
      },
      "source": [
        "##Sets a learning rate scheduler, compiles the model, and trains\n",
        "\n",
        "I've experimented with larger learning rates than 0.001, finding that five times this is too high as loss is very non-monatonic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6a8f7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6a8f7c",
        "outputId": "7ca01f24-d11c-4826-80e4-9c7f9d143833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 30s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 2.5000e-04\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 2.5000e-04\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 2.5000e-04\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 2.5000e-04\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 2.5000e-04\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 1.2500e-04\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 28s 55ms/step - loss: 0.0037 - lr: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "if train:\n",
        "  # Set the learning rate (I find that .005 is too large)\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  simple_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "\n",
        "  simple_autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch\n",
        "  simple_encoder.save(f'simple_encoder_{save_string}.keras')\n",
        "  simple_decoder.save(f'simple_decoder_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7rHxc33vp9W3",
      "metadata": {
        "id": "7rHxc33vp9W3"
      },
      "source": [
        "# Encoder-decoder 2:  \n",
        "\n",
        "This takes out the dense layers and replaces it with 1x1 convolution layer.  This makes a pure CNN encoder-decoder and the output now is in terms of pixels and channels rather than one vector.  This felt more physically motivated.  Now n=4 and 16 channels is the same compression as n=2 previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658b8wytptj2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658b8wytptj2",
        "outputId": "a6e9d402-0546-4180-d210-0305426ee84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading saved modelCNN_encoder_n4_nc256_nfc16_d0_logL1w+00.keras\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=4 #number of layers (needs to be >2)\n",
        "number_channels = 256 #these are intermediate  channels\n",
        "number_final_channels = 16  # if n=4 and number_final_channels = 16, this is eqivalent to n=2 decompression in other encoders\n",
        "\n",
        "act_string = 'ReLU' #LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_nfc{number_final_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_CNN_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=None, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "\n",
        "    model.add(layers.Conv2D(number_final_channels, (1, 1), activation=None, padding='same',\\\n",
        "          kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "    #model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "    #          kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_CNN_decoder(original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer( (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_final_channels)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=None, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "model_name = f'CNN_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    print(f\"loading saved model{model_name}\")\n",
        "    CNN_encoder = load_model(model_name)\n",
        "    CNN_decoder = load_model(f'CNN_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  CNN_encoder = create_CNN_encoder(original_shape, n)\n",
        "  CNN_decoder = create_CNN_decoder(original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "CNN_autoencoder = models.Sequential([CNN_encoder, CNN_decoder])\n",
        "\n",
        "CNN_encoder.summary()\n",
        "CNN_decoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y0geI0hW3WnE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0geI0hW3WnE",
        "outputId": "4e711990-1ec7-42a5-d66f-c7cc11599151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 169s 311ms/step - loss: 0.0181 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0075 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0071 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0066 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0065 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0063 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0060 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0057 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0055 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0053 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0052 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0051 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0051 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0049 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0052 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0046 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0046 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "if train:\n",
        "\n",
        "  learning_rate = .001\n",
        "\n",
        "  CNN_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")\n",
        "  CNN_autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch\n",
        "  CNN_encoder.save(f'CNN_encoder_{save_string}.keras')\n",
        "  CNN_decoder.save(f'CNN_decoder_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OueELMBd7HuO",
      "metadata": {
        "id": "OueELMBd7HuO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ifU_ceKxiGtH",
      "metadata": {
        "id": "ifU_ceKxiGtH"
      },
      "source": [
        "#Encoder Decoder 3 (residual connections)\n",
        "\n",
        "This now is the same CNN as our first but with residual connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KbAkbrpXiMrT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbAkbrpXiMrT",
        "outputId": "2d307fad-b679-4677-8eea-ee070c761086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 64, 64, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 64, 64, 64)           640       ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 64, 64, 64)           256       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 64, 64, 64)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)           0         ['activation_6[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 64)           36928     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 32, 32, 64)           256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 32, 32, 64)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 32, 32, 64)           256       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 32, 32, 64)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 64)           0         ['activation_8[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 16384)                0         ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 256)                  4194560   ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4269824 (16.29 MB)\n",
            "Trainable params: 4269440 (16.29 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 16384)                4210688   ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 16, 16, 64)           0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 64)           256       ['reshape_2[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2D  (None, 16, 16, 64)           36928     ['activation_9[0][0]']        \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_8[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2D  (None, 16, 16, 64)           36928     ['activation_10[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_9[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 64)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['activation_11[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2  (None, 32, 32, 64)           36928     ['up_sampling2d_4[0][0]']     \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_transpose_10[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 1)            65        ['up_sampling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4322305 (16.49 MB)\n",
            "Trainable params: 4321921 (16.49 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "n=2\n",
        "number_channels = 64\n",
        "\n",
        "act_string = 'ReLU'# LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "\n",
        "def create_encoder_residconnect(input_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Initial Convolutional Layer\n",
        "    x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Additional Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Flatten and Dense Layer\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "def create_decoder_residconnect(encoded_length, original_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=(encoded_length,))\n",
        "    x = inputs\n",
        "\n",
        "    # Dense layer\n",
        "    x = layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    x = layers.Reshape((original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "\n",
        "    # Upsampling Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Final Conv2DTranspose to get back to original shape\n",
        "    x = layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "model_name = f'encoder_residconnect_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    print(f\"loading saved model{model_name}\")\n",
        "    encoder_residconnect= load_model(f'encoder_residconnect_{save_string}.keras')\n",
        "    decoder_residconnect = load_model(f'decoder_residconnect_{save_string}.keras')\n",
        "\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  encoder_residconnect = create_encoder_residconnect(original_shape , n)\n",
        "  decoder_residconnect = create_decoder_residconnect(encoded_length,original_shape, n)\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "autoencoder_residconnect = models.Sequential([encoder_residconnect, decoder_residconnect])\n",
        "\n",
        "encoder_residconnect.summary()\n",
        "decoder_residconnect.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fVrF4DWCQ3eG"
      },
      "id": "fVrF4DWCQ3eG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qTDG33XFy2Ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTDG33XFy2Ec",
        "outputId": "b6ea7439-4321-41df-8b5d-bea84e504fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 64s 119ms/step - loss: 0.4602 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.3051 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.2714 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.2558 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.2472 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.2419 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2384 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2360 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2329 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2306 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2298 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2282 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2272 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2267 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2262 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2253 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2247 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2251 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.2240 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.2239 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "if train:\n",
        "  # Set the learning rate\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  autoencoder_residconnect.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")\n",
        "\n",
        "  autoencoder_residconnect.fit(WL_tensor, WL_tensor, epochs=20,batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()\n",
        "  encoder_residconnect.save(f'encoder_residconnect_{save_string}.keras')\n",
        "  decoder_residconnect.save(f'decoder_residconnect_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95cc9323",
      "metadata": {
        "id": "95cc9323"
      },
      "source": [
        "## Encoder-decoder 4: most complex model\n",
        "\n",
        "I've added 2*(n-1) additional layers, half 1x1 convolutions and half 3x3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82c7819",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b82c7819",
        "outputId": "5cb7302e-2cc3-4943-ea98-0c9af5f9d2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 32)        320       \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 64)        2112      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 32, 32, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 32, 32, 64)        4160      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 32, 32, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4341312 (16.56 MB)\n",
            "Trainable params: 4341056 (16.56 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 16384)             4210688   \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2  (None, 16, 16, 64)        36928     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_transpose_12 (Conv2  (None, 16, 16, 64)        4160      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_transpose_13 (Conv2  (None, 16, 16, 64)        36928     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " up_sampling2d_6 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_14 (Conv2  (None, 32, 32, 64)        4160      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_transpose_15 (Conv2  (None, 32, 32, 32)        18464     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " up_sampling2d_7 (UpSamplin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 64, 64, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4311873 (16.45 MB)\n",
            "Trainable params: 4311617 (16.45 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "n=2\n",
        "number_channels = 64\n",
        "number_dense = 2\n",
        "\n",
        "act_func = 'ReLU' #LeakyReLU(alpha=0.1)\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "if number_dense > 1:\n",
        "  save_string = save_string + f'_nd{number_dense}'\n",
        "\n",
        "def create_encoder(input_shape, n, number_channels=64, act_string=act_func, regularizer=regularizer):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    for i in range(number_dense):\n",
        "      model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_decoder(encoded_length, original_shape, n, number_channels=64, act_string=act_func, regularizer=regularizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    for i in range(number_dense-1):\n",
        "      model.add(layers.Dense(units=np.prod(encoded_length*64), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), 64)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "#load_saved = 0\n",
        "model_name = f'encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    print(f\"loading saved model{model_name}\")\n",
        "    encoder= load_model(f'encoder_{save_string}.keras')\n",
        "    decoder = load_model(f'decoder_{save_string}.keras')\n",
        "else:\n",
        "    if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model...\")\n",
        "    # Combine the encoder and decoder to create the autoencoder\n",
        "    encoder = create_encoder(original_shape , n)\n",
        "    decoder = create_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "autoencoder = models.Sequential([encoder, decoder])\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0659942d",
      "metadata": {
        "id": "0659942d"
      },
      "source": [
        "# compile and train complex CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da431d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7da431d7",
        "outputId": "c60d3339-42e7-4ee4-93a6-1102926f2375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 59s 108ms/step - loss: 0.4171 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.3163 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2942 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2823 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2758 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2707 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2669 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2637 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2612 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2591 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2580 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2559 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2549 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2533 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2525 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2517 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2509 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2501 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 55s 108ms/step - loss: 0.2495 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "352/512 [===================>..........] - ETA: 17s - loss: 0.2491"
          ]
        }
      ],
      "source": [
        "if train:\n",
        "  # Set the learning rate\n",
        "  learning_rate = 0.001\n",
        "  autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "  autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr])\n",
        "  encoder.save(f'encoder_{save_string}.keras')\n",
        "  decoder.save(f'decoder_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Switching our most complex to layer normalization\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Lh-XMEsRNVy"
      },
      "id": "7Lh-XMEsRNVy"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LayerNormalization, Dropout\n",
        "\n",
        "\n",
        "\n",
        "n=2\n",
        "number_channels = 64\n",
        "number_dense = 2\n",
        "\n",
        "act_func = 'ReLU'\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "if number_dense > 1:\n",
        "  save_string = save_string + f'_nd{number_dense}'\n",
        "\n",
        "def create_encoder(input_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(layers.AveragePooling2D((2, 2)))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    for i in range(number_dense):\n",
        "      model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_func, kernel_regularizer=regularizer))\n",
        "      model.add(LayerNormalization())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_decoder(encoded_length, original_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    for i in range(number_dense-1):\n",
        "      model.add(layers.Dense(units=np.prod(encoded_length*64), activation=act_func, kernel_regularizer=regularizer))\n",
        "      model.add(LayerNormalization())\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), 64)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same'))\n",
        "        model.add(LayerNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "#load_saved = 1\n",
        "model_name = f'motivated_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    print(f\"loading saved model{model_name}\")\n",
        "    motivated_encoder= load_model(f'encoder_{save_string}.keras')\n",
        "    motivated_decoder = load_model(f'decoder_{save_string}.keras')\n",
        "else:\n",
        "    if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model...\")\n",
        "    # Combine the encoder and decoder to create the autoencoder\n",
        "    motivated_encoder = motivated_create_encoder(original_shape , n)\n",
        "    motivated_decoder = motivated_create_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "motivated_autoencoder = models.Sequential([motivated_encoder, motivated_decoder])\n",
        "\n",
        "motivated_encoder.summary()\n",
        "motivated_decoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngUU3FI0RRJs",
        "outputId": "28f6f8b6-979d-49a7-b6bf-c874712856b0"
      },
      "id": "ngUU3FI0RRJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 32)        320       \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 64, 64, 64)        2112      \n",
            "                                                                 \n",
            " average_pooling2d_4 (Avera  (None, 32, 32, 64)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " layer_normalization_20 (La  (None, 32, 32, 64)        128       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 64)        4160      \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " layer_normalization_21 (La  (None, 32, 32, 64)        128       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_5 (Avera  (None, 16, 16, 64)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               4194560   \n",
            "                                                                 \n",
            " layer_normalization_22 (La  (None, 256)               512       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " layer_normalization_23 (La  (None, 256)               512       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " layer_normalization_24 (La  (None, 256)               512       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4408384 (16.82 MB)\n",
            "Trainable params: 4408384 (16.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 16384)             4210688   \n",
            "                                                                 \n",
            " layer_normalization_25 (La  (None, 16384)             32768     \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 16384)             268451840 \n",
            "                                                                 \n",
            " layer_normalization_26 (La  (None, 16384)             32768     \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 16384)             268451840 \n",
            "                                                                 \n",
            " layer_normalization_27 (La  (None, 16384)             32768     \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_10 (Conv2  (None, 16, 16, 64)        36928     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " layer_normalization_28 (La  (None, 16, 16, 64)        128       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_transpose_11 (Conv2  (None, 16, 16, 64)        4160      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_transpose_12 (Conv2  (None, 16, 16, 64)        36928     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " layer_normalization_29 (La  (None, 16, 16, 64)        128       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_13 (Conv2  (None, 32, 32, 64)        4160      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv2d_transpose_14 (Conv2  (None, 32, 32, 32)        18464     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " up_sampling2d_5 (UpSamplin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541313601 (2.02 GB)\n",
            "Trainable params: 541313601 (2.02 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train:\n",
        "  # Set the learning rate\n",
        "  learning_rate = 0.001\n",
        "  motivated_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "  motivated_autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr])\n",
        "  motivated_encoder.save(f'encoder_{save_string}.keras')\n",
        "  motivated_decoder.save(f'decoder_{save_string}.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oMjNPNKSx-R",
        "outputId": "e329ba43-79d4-4b4f-d4c4-99a957cef8e8"
      },
      "id": "7oMjNPNKSx-R",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 92s 168ms/step - loss: 0.4928 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3497 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3272 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3208 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 86s 167ms/step - loss: 0.3187 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 86s 167ms/step - loss: 0.3175 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3168 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3160 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3155 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3149 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 86s 167ms/step - loss: 0.3145 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3141 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3137 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3134 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3131 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3128 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3126 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3122 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3120 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 86s 168ms/step - loss: 0.3117 - lr: 0.0010\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-02ff959f5b7c>\", line 7, in <cell line: 1>\n",
            "    motivated_encoder.save(f'encoder_{save_string}.keras')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/lib/python3.10/zipfile.py\", line 1251, in __init__\n",
            "    self.fp = io.open(file, filemode)\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'encoder_n2_nc64_d0_logL1w+00_nd2.keras'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-02ff959f5b7c>\", line 7, in <cell line: 1>\n",
            "    motivated_encoder.save(f'encoder_{save_string}.keras')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/lib/python3.10/zipfile.py\", line 1251, in __init__\n",
            "    self.fp = io.open(file, filemode)\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'encoder_n2_nc64_d0_logL1w+00_nd2.keras'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-02ff959f5b7c>\", line 7, in <cell line: 1>\n",
            "    motivated_encoder.save(f'encoder_{save_string}.keras')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/lib/python3.10/zipfile.py\", line 1251, in __init__\n",
            "    self.fp = io.open(file, filemode)\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'encoder_n2_nc64_d0_logL1w+00_nd2.keras'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FndU2Dzi3GSJ",
      "metadata": {
        "id": "FndU2Dzi3GSJ"
      },
      "source": [
        "#This shows images from the various encoders/decoders\n",
        "\n",
        "change number_dcoders to compare more decoders, if they are loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca90b78c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "ca90b78c",
        "outputId": "9595cd33-52db-4313-9380-3b324961055d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.05\n",
            "MAE loss for averaged map =  0.00465\n",
            "MAE loss for decoder 0 =  0.00424\n",
            "MAE loss for decoder 1 =  0.005333\n",
            "MAE loss for decoder 2 =  0.004898\n",
            "MAE loss for decoder 3 =  0.006355\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE loss for averaged map =  0.005592\n",
            "MAE loss for decoder 0 =  0.004887\n",
            "MAE loss for decoder 1 =  0.006386\n",
            "MAE loss for decoder 2 =  0.005577\n",
            "MAE loss for decoder 3 =  0.007236\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAAEACAYAAAAA++nbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFIklEQVR4nO29ebglVXX3v6rqjHfukYZuaZpBBFRkCIiAjShvGyARDBrAQBMN/iRKQt4o8Y0hYMQpiCESBaM8rQImKCIS4xAHiBEJYCSgaMvYLQ30dLvveMaq2r8/2j619j57Lc49dNPnXr6f5+Gh7t61d+259qnea30DY4whAAAAAAAAAAAAAABATxDu6QIAAAAAAAAAAAAAAAAy8MEOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoIfDBDgAAAAAAAAAAAACAHgIf7AAAAAAAAAAAAAAA6CHwwQ4AAAAAAAAAAAAAgB4CH+wAAAAAAAAAAAAAAOgh8MEOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoIfDBDgAAdgHr1q2jIAjoC1/4wi7L8wtf+AIFQUDr1q3bZXkCAHY9mP8AvLjBGgDAixfMf7A7edF9sNs5+H/605/u6aIQEVGlUqErrriC7rrrro7uv+uuuygIArr11lt3b8H2IKOjo3TVVVfRa1/7Wlq0aBGNjIzQq1/9arrlllv2dNHAbmTn3Nz5X6lUon322YdWrVpFn/rUp2hycnJPF7FnueKKKygIAtq6deueLspuJU1T+vu//3tasWIFlUoleuUrX0n/8i//0nV+Tz31FH3wgx+kY445hubNm0cLFy6kk046ib7//e/vwlKDTsD8754Xy/z/8Ic/TL//+79Pe+21FwVBQFdcccXzyg97jd4Ca0D3vBjWgLVr19Kll15Kr3rVq2hwcJD23ntvOu20057X7zmsAb0D5n/3vBjm/zPPPEN/9Ed/RAcffDANDg7SyMgIHXPMMfTFL36RjDFd5Tmb5v+L7oNdr1GpVOiDH/xgxx/sXgzcc8899IEPfIDmz59Pf/M3f0Mf/vCHqa+vj84++2y6/PLL93TxwG7m7/7u7+jGG2+k6667ji6++GIiIrrkkkvoFa94BT300EN7uHRgT/KBD3yA/uqv/opOOeUUuvbaa2nfffelc889l/71X/+1q/y+8Y1v0Mc//nE68MAD6corr6TLLruMJicn6ZRTTqE1a9bs4tKDTsD8BxJ/8zd/Q/fffz8dccQRuyQ/7DV6E6wBwMfnP/95+tznPkdHH300XX311fR//+//pV//+tf06le/uut/ZMMa0Htg/gMfW7dupQ0bNtBZZ51Fn/jEJ+jKK6+kvffemy644AL6wAc+0FWes2r+mxcZa9asMURk7r///j1dFGOMMVu2bDFEZC6//PKO7r/zzjsNEZmvfvWru7dge5AnnnjCrFu3zgpL09ScfPLJplgsmqmpqT1UMrA70ebmD37wA1Mul83y5ctNpVLZA6V7bp588klDRGbNmjW7LM+dbfLkk0+q911++eWGiMyWLVt22bN7jQ0bNph8Pm/e/e53t8LSNDUnnniiWbZsmYnjeMZ5/uIXv2hrs1qtZl72speZZcuWPe8yg87B/G8H899mZzvMdN8kgb1Gb4E1oB2sARk//elPzeTkpBW2detWs2jRInP88cd3lSfWgN4B878dzP/n5vTTTzf9/f1d/QaYTfMfJ+yI6IILLqCBgQF6+umn6YwzzqCBgQFatGgRvfe976UkSVr37bRP/8QnPkH/8A//QMuXL6dyuUwrV66kX/ziF1aeJ510Ep100kneZ+23336t/BYtWkRERB/84Adbx4Bnauax8yjsI488Qn/0R39Ew8PDtGjRIrrsssvIGENPPfUUvelNb6KhoSFasmQJXX311Vb6RqNBf/u3f0tHHXUUDQ8PU39/P5144ol05513tj1rdHSUzjvvPBoaGqKRkRFavXo1Pfjgg167/bVr19JZZ51F8+fPp1KpREcffTTdcccdz1mfFStW0PLly62wIAjojDPOoHq9Tk888cSM2gfMfk4++WS67LLLaP369XTTTTdZcZ2Os7GxMfqLv/gL2m+//ahYLNKyZcvo/PPPt46Qb968md7xjnfQXnvtRaVSiQ4//HD64he/6M3rggsuoOHh4dY8GBsb85a90/I9/PDDdPLJJ1O5XKZly5bRlVdeSWmazrClMk466SR6+ctfTg899BCtXLmS+vr66MADD2yZ0//nf/4nHXvssVQul+nggw9u+xfq9evX05/+6Z/SwQcfTOVymRYsWEBvectbvL40dj6Dl33NmjVe3xvf/va36cQTT6T+/n4aHByk0047jR5++OHnrM83vvENajab9Kd/+qetsCAI6KKLLqINGzbQPffcM+M2Ouyww2jhwoVWWLFYpFNPPZU2bNgAE4weAfN/5sy1+U9Erb3TrgJ7jdkD1oCZM9fWgKOOOooGBgassAULFtCJJ55Iv/rVr2bWOL8Fa8DsAPN/5sy1+S+x3377UaVSoUajMeO0s2n+5/Z0AXqFJElo1apVdOyxx9InPvEJ+v73v09XX301HXDAAXTRRRdZ937pS1+iyclJeve73021Wo3+8R//kU4++WT6+c9/TnvttVfHz1y0aBFdd911dNFFF9GZZ55Jb37zm4mI6JWvfGVXdfjDP/xDOuSQQ+hjH/sY/fu//ztdeeWVNH/+fPrsZz9LJ598Mn384x+nm2++md773vfS7/zO79BrX/taIiKamJigz3/+83TOOefQhRdeSJOTk3TDDTfQqlWr6L777qNXvepVRLTDf9Tv/d7v0X333UcXXXQRvexlL6NvfOMbtHr16rayPPzww3T88cfT0qVL6f3vfz/19/fTV77yFTrjjDPoa1/7Gp155pkzrt/GjRuJiNp+YIMXB+eddx799V//Nf3Hf/wHXXjhhUTU+Tibmppqbere/va305FHHklbt26lO+64gzZs2EALFy6karVKJ510Ej322GP0nve8h1asWEFf/epX6YILLqCxsTH68z//cyIiMsbQm970Jvrxj39M73rXu+iQQw6hr3/9689rHmzcuJFe97rXURzHrfv++Z//mcrl8vNqs+3bt9Ppp59OZ599Nr3lLW+h6667js4++2y6+eab6ZJLLqF3vetddO6559JVV11FZ511Fj311FM0ODhIRET3338//eQnP6Gzzz6bli1bRuvWraPrrruOTjrpJPrlL39JfX19RET09NNP0+te9zoKgoD+3//7f9Tf30+f//znqVgstpXnxhtvpNWrV9OqVavo4x//OFUqFbruuuvohBNOoAceeED9Qf7AAw9Qf38/HXLIIVb4Mccc04o/4YQTnld77WTjxo3U19fXqiPY82D+z5y5NP9fSLDX6E2wBsycF8MasHHjxl0+V7EG9B6Y/zNnLs7/arVK09PTNDU1Rf/5n/9Ja9asoeOOO+55txWnJ+f/Hj3ftwfwHbldvXq1ISLzd3/3d9a9RxxxhDnqqKNaf+887loul82GDRta4ffee68hIvMXf/EXrbCVK1ealStXtj1/9erVZvny5a2/d4VJ7M6jsO985ztbYXEcm2XLlpkgCMzHPvaxVvj27dtNuVw2q1evtu6t1+vWc7Zv32722msv8/a3v70V9rWvfc0QkbnmmmtaYUmSmJNPPrntGPDrX/9684pXvMLUarVWWJqm5jWveY056KCDOqorZ3R01CxevNiceOKJM04LZgedmKsPDw+bI444ovV3p+Psb//2bw0Rmdtuu60tzzRNjTHGXHPNNYaIzE033dSKazQa5rjjjjMDAwNmYmLCGGPM7bffbojI/P3f/33rvjiOzYknntj1PLjkkksMEZl77723FbZ582YzPDzc9XH4lStXGiIyX/7yl1tha9euNURkwjA0//3f/90K/+53v9tWdp/ZwT333GOIyHzpS19qhV188cUmCALzwAMPtMJGR0fN/PnzrbJPTk6akZERc+GFF1p5bty40QwPD7eFu5x22mlm//33bwufnp42RGTe//73q+k75dFHHzWlUsmcd955uyQ/0BmY/5j/nbKrTGJ9YK+x58AagDVgpvzoRz8yQRCYyy67bMZpJbAG7Bkw/zH/O+GjH/2oIaLWf69//evNb37zm47SdkKvzn+YxDLe9a53WX+feOKJ3uOQZ5xxBi1durT19zHHHEPHHnssfetb39rtZdT4kz/5k9Z1FEV09NFHkzGG3vGOd7TCR0ZG6OCDD7bqFUURFQoFItpxim7btm0UxzEdffTR9LOf/ax133e+8x3K5/Otf9kgIgrDkN797ndb5di2bRv98Ic/pLe+9a00OTlJW7dupa1bt9Lo6CitWrWKHn30UXr66ac7rleapvS2t72NxsbG6Nprr+28QcCcY2BgoGWmOJNx9rWvfY0OP/xw78nOIAiIiOhb3/oWLVmyhM4555xWXD6fpz/7sz9r/UvOzvtyuZx18jaKopZz3J3MpHzf+ta36NWvfnXrtBjRjhO4b3vb2553e5199tmtvw8++GAaGRmhQw45hI499thW+M5rvi7wf61qNps0OjpKBx54II2MjLStC8cdd1zrJC4R0fz589vK/r3vfY/GxsbonHPOabXF1q1bKYoiOvbYY70m+Jxqter9F7tSqdSKf75UKhV6y1veQuVymT72sY897/zArgXzf+btNVfm/wsB9hq9D9aAmbfXXF0DNm/eTOeeey6tWLGCLr300hmllcAa0Ntg/s+8veba/D/nnHPoe9/7Hn35y1+mc889l4h2zf6fqLfnP0xif0upVGr5k9vJvHnzaPv27W33HnTQQW1hL33pS+krX/nKbitfJ+y7777W38PDw1QqldqOdA4PD9Po6KgV9sUvfpGuvvpqWrt2LTWbzVb4ihUrWtfr16+nvffeu81M7MADD7T+fuyxx8gYQ5dddhlddtll3rJu3rzZ+uipcfHFF9N3vvMd+tKXvkSHH354R2nA3GRqaooWL15MRDMbZ48//jj9wR/8gZr3+vXr6aCDDqIwtP8dY6cJ5vr161v/33vvvdt8qRx88MHW3zMp3/r1662Xp5TnTFm2bFlrM7KT4eFheslLXtIWRkTWeletVumjH/0orVmzhp5++mlLNn18fLx1vX79ejruuOPanu2uC48++igR7fBF4mNoaEitS7lcpnq93hZeq9Va8c+HJEno7LPPpl/+8pf07W9/m/bZZ5/nlR/Y9WD+z4y5NP9fCLDX6H2wBsyMuboGTE9P0+mnn06Tk5P04x//uK0vugVrQG+D+T8z5uL8X758ecvv3DnnnEPvfOc76Q1veAP9+te/ft6/A3p5/uOD3W+JomiX5hcEgTW4d8JFLHY1vjpI9eJlu+mmm+iCCy6gM844g973vvfR4sWLKYoi+uhHP0qPP/74jMux00nme9/7Xlq1apX3HnciS3zwgx+kz3zmM/Sxj32MzjvvvBmXBcwdNmzYQOPj462xsyvH2e6gF8onzf9O1oWLL76Y1qxZQ5dccgkdd9xxNDw8TEEQ0Nlnn92VI9ydaW688UZasmRJW3wup7+O9t57b7rzzjvJGGNtQJ599lkiouf9ge3CCy+kb37zm3TzzTeLGwqw58D8nzlzaf7vbrDX6H2wBsycubgGNBoNevOb30wPPfQQffe736WXv/zlMy6LD6wBvQ3m/8yZi/Pf5ayzzqLPfe5z9KMf/Uhs507o9fmPD3ZdsPMrMeeRRx6xnCXOmzfPa0678wv9Ttwv33uCW2+9lfbff3+67bbbrPJcfvnl1n3Lly+nO++8kyqVinXK7rHHHrPu23///Ylox1HiN7zhDV2X69Of/jRdccUVdMkll9Bf/dVfdZ0PmBvceOONREStBXkm4+yAAw5oU3J2Wb58OT300EOUpqn1L2xr165txe/8/w9+8AOampqy/oXt17/+tZXfTMq3fPly77ri5vlCcuutt9Lq1astVelardamhLV8+fK2NYCofV044IADiIho8eLFXa0Lr3rVq+jzn/88/epXv6JDDz20FX7vvfe24rvlfe97H61Zs4auueYayxwC9A6Y/y8svTb/dyfYa8wOsAa8sPTiGpCmKZ1//vn0gx/8gL7yla/QypUru8rHBWtA74P5/8LSi/Pfx05zWH7qb6bMhvkPH3ZdcPvtt1s+2O677z6699576Xd/93dbYQcccACtXbuWtmzZ0gp78MEH6e6777by2vnhS5KDfiHY+aWdf1m/99576Z577rHuW7VqFTWbTfrc5z7XCkvTlD796U9b9y1evJhOOukk+uxnP9s6/cLhbSJxyy230J/92Z/R2972NvrkJz85o/qAuccPf/hD+tCHPkQrVqxo+UWYyTj7gz/4A3rwwQfp61//ett9O8f9qaeeShs3bqRbbrmlFRfHMV177bU0MDDQ2hieeuqpFMcxXXfdda37kiRp83cwk/Kdeuqp9N///d903333WfE333yz3jC7kSiK2k4JX3vttW2nhFetWkX33HMP/e///m8rbNu2bW1lX7VqFQ0NDdFHPvIRy+x+J8+1LrzpTW+ifD5Pn/nMZ1phxhi6/vrraenSpfSa17ym06pZXHXVVfSJT3yC/vqv/7qlAgZ6C8z/F55em/+7C+w1ZgdYA154enENuPjii+mWW26hz3zmM/TmN795BrWRwRrQ+2D+v/D02vyX4m+44QYKgoCOPPJINb3EbJn/OGHXBQceeCCdcMIJdNFFF1G9XqdrrrmGFixYYDk9ffvb306f/OQnadWqVfSOd7yDNm/eTNdffz0ddthhNDEx0bqvXC7ToYceSrfccgu99KUvpfnz59PLX/7yXXbEuxNOP/10uu222+jMM8+k0047jZ588km6/vrr6dBDD6WpqanWfWeccQYdc8wx9Jd/+Zf02GOP0cte9jK64447aNu2bURknxb89Kc/TSeccAK94hWvoAsvvJD2339/2rRpE91zzz20YcMGevDBB8Xy3HfffXT++efTggUL6PWvf33bpH/Na17T+pcLMPf49re/TWvXrqU4jmnTpk30wx/+kL73ve/R8uXL6Y477miJDBB1Ps7e97730a233kpvectb6O1vfzsdddRRtG3bNrrjjjvo+uuvp8MPP5ze+c530mc/+1m64IIL6H/+539ov/32o1tvvZXuvvtuuuaaa1pS57/3e79Hxx9/PL3//e+ndevW0aGHHkq33Xab9193Oi3fpZdeSjfeeCO98Y1vpD//8z9vSbrv/Be/PcHpp59ON954Iw0PD9Ohhx5K99xzD33/+9+nBQsWWPddeumldNNNN9Epp5xCF198cUvSfd9996Vt27a11oWhoSG67rrr6LzzzqMjjzySzj77bFq0aBH95je/oX//93+n448/nv7pn/5JLM+yZcvokksuoauuuoqazSb9zu/8Dt1+++30X//1X3TzzTdbR/y/8IUv0B//8R/TmjVr6IILLhDz/PrXv06XXnopHXTQQXTIIYfQTTfdZMWfcsoptNdee3XReqBbMP8x/yVuvPFGWr9+PVUqFSIi+tGPfkRXXnklERGdd955rRMQd911F73uda+jyy+/nK644goxP+w1ehOsAVgDfFxzzTX0mc98ho477jjq6+tre1+feeaZ1N/fT0RYA2YzmP+Y/z4+/OEP0913301vfOMbW3l/7Wtfo/vvv58uvvhiy7x4Ts7/F0CJtqfwyUavXr3a9Pf3t927UyZ5J08++aQhInPVVVeZq6++2rzkJS8xxWLRnHjiiebBBx9sS3/TTTeZ/fff3xQKBfOqV73KfPe73zWrV682y5cvt+77yU9+Yo466ihTKBQMEZnLL79cLP+dd95piMh89atfbSsnl3PW6rVy5Upz2GGHtf5O09R85CMfMcuXLzfFYtEcccQR5pvf/Ka3rFu2bDHnnnuuGRwcNMPDw+aCCy4wd999tyEi86//+q/WvY8//rg5//zzzZIlS0w+nzdLly41p59+urn11lvF+hmT9ZH0H5edBnMHt98LhYJZsmSJOeWUU8w//uM/tiTVXTodZ6Ojo+Y973mPWbp0qSkUCmbZsmVm9erVZuvWra17Nm3aZP74j//YLFy40BQKBfOKV7zCO95GR0fNeeedZ4aGhszw8LA577zzzAMPPOAdn52W76GHHjIrV640pVLJLF261HzoQx8yN9xww/OSdOfzfCfLly83p512Wls4EZl3v/vdrb+3b9/eaouBgQGzatUqs3btWrN8+XKzevVqK+0DDzxgTjzxRFMsFs2yZcvMRz/6UfOpT33KEJHZuHGjde+dd95pVq1aZYaHh02pVDIHHHCAueCCC8xPf/pTtY7GGJMkSWutKhQK5rDDDjM33XRT233XXnutISLzne98R81vZ7tJ/915553PWSawa8D8x/x/LlauXNnRXP23f/s3Q0Tm+uuvV/PDXqO3wBqANUBj9erV6nzlbYQ1YPaB+Y/5r/Ef//Ef5vTTTzf77LOPyefzZnBw0Bx//PFmzZo1Jk1T6965OP8DYzzKCMDLunXraMWKFXTVVVfRe9/73j1dnJ7h9ttvpzPPPJN+/OMf0/HHH7+niwMA6AEuueQS+uxnP0tTU1O7XNTnuXjrW99K69ats8wLAAAvHHty/l966aX0L//yL/TYY49RsVh8QZ8NANgB1gAAXrxg/u9a4MMOzIidzh13stNuf2hoqGv7cQDA7MZdF0ZHR+nGG2+kE0444QV/URtj6K677mqZygEAdi+9NP+JiO6880667LLL5sxGHYBeB2sAAC9eMP93P/BhB2bExRdfTNVqlY477jiq1+t022230U9+8hP6yEc+QuVyeU8XDwCwBzjuuOPopJNOokMOOYQ2bdpEN9xwA01MTNBll132gpclCALavHnzC/5cAF6s9NL8JyK6//7798hzAXixgjUAgBcvmP+7H3ywAzPi5JNPpquvvpq++c1vUq1WowMPPJCuvfZaes973rOniwYA2EOceuqpdOutt9I///M/t9SabrjhBnrta1+7p4sGANjNYP4D8OIGawAAL14w/3c/8GEHAAAAAAAAAAAAAEAPAR92AAAAAAAAAAAAAAD0EPhgBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BAdi04c+c5Ptq6b/YEVlxbYH3aUhRHiwtgp1HTmVi9ssvsSN112nwlY5oF2Xxae5uwbA+bNz7ifMllcyltNqa+VXPk0GqTZtdsWnaQhIooaWQFztSzShE4d0+y+Zl9WKLcteH2jZvZH6qgzp/ksXXMgu04K9n25apZHVPOXm4goX2F/d9m2SSFLGBeza+OMdmk8um3L/47qbGw6fRWX2HOZYG5j2H4QL++vPvwX/kL0IIdf/A9iXCIpZyt9GNXluLDhd62Zq3mDd+QnpCEiazxzUmUFdNc5O50cJ5XDHVccaSwSyWtCvirXl695Lu4c3glfD1ySkhgll6Epx2l9FTWECMXdKl+HXLR+lNZlbWxKY4mIKO7zh9fmy2VY+6HZsQa8/L3y/JfaUXufhVI/k73OWuHKmNL6xQhjPs0rabR3dqLEKfNcQluHAqFe2hgNEqUxhKGorWndtsVMy0CktJ/Wv0r5xHcTEaUFoSDKs7S1VVrHk5Jc4Z9/cnbMfyKiw94vrwGR8G7OVbpY64nUPhBRxpU0x9S5p8xldf4J76pEeU9pa5E0x3I1pW2VtVKaL7EyTuMu9gBaG/HfFS5SfbV5rv/27PDHRIf5ub9vOHHZnzApe4OJiOjhj82ONeAV/1ee/9K7PlL2qTnhPU8kjwH1/drF/NfmpPbucH9bc6Sx3e2euJt3ojp+hTpra5C2Tkpo9XW/53D4d4pOSSNl/yLs/4jkOqv7ISU/8TuXUt8HP9XZ/McJOwAAAAAAAAAAAAAAegh8sAMAAAAAAAAAAAAAoIfo+JAjPwLommjwo6v8yHLbfVaGLFw54sqP2brHZ7nZBz+u6R5X5Pnr9eCmn865xsB/7R7RtvJkz1WP8WqmHtKpTLd4/FlCfxDJx0ZdMzmrzVgS99gzP07asdlv4r/ecaM/P7cdrHZ2+5G3tWUCbd/Hj8lrZi5WGnYMOs3bafjY4qY2zSH7PskkEQAAAAAAAAAAAIAIJ+wAAAAAAAAAAAAAAOgp8MEOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoITr2YZcwn1yu3DJXzC5MMH9djlswS8Kd+ypz/JNxX3Uhk0fO1RxHcCz/uC/79pimdoaWRDDz4eb6NAu4fzJFtluVUmZx3N+b6y/PdOgTT5UxZ3C/aFyO2JVH5o9NWCHiPrvN4j5/YXM15bmszcKGfR+vB5eHT4r2c8Nm9rdVd6f9eNu6/uf4WOX1ih1ZdS45bfnmc8YjL0dS4uH2jfy5zQGW90unrPv6CorWdQ/jth9H8tForQcO+Sk5TvIp6M4jjujvkWQJ9lSVdFdk2xUJ9qghRChlT5T1ho85jjsXny+abLu7PnAk6XYTyhXmc8UlPy08J/aHE+mS7lo/iv4kjdJZyjhrDvgja0sUTfdZguprVhgD6jypy/lFdX+6Tn2NukjzXJv//D3aVg5lMovt1F3Rledo66ecTprn2vzX5qtUDm2t1tpCGktafmrZS8raIKytevm0tcYfXp+/izt/T6Eti8K418Yi39+3xUlLpro2K32T94cbJY3rD7vTOEqUl4SUX4c+oDvOT9sPCXGaf2XtPao8SY5R3tnimNH2f0r7qX0loVRXa4vmoD+8Pm/2rwHS+kZEYt+oTd/FetLte0WcQ9o8UcaoNqakV3OgrIXafBWj1N88M4/T3qPqfiiRKizn1w3S7zgivT/031f+PLWx3s1ane6CnwA4YQcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHZvEWiaSzglCbtrCjwq6Jlvc1JUfa3ePOXIzGs3sg5fDOoboHI3kZi/8WW3HJLlpqnsUluVvmfm4pprs2CM333GPk/J24mlUE1heX+e5/O/AyOWz0rA6Bc6RVl7e5lAW51ox8TxyU1kazRSSH12N3aPlgqm0az6Vn+b20G6hhOc6bcuP/1pmxIrJBR8X7hFmbhLM8w7UM9wAAAAAAAAAAAAANjhhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BAdm8Ryc0JXQZWrxlrWf4oyasRVPh31V26eyU0QNUU3niZoUwvJ0oWGm9va+VlmkY6JqFXH1H9NZJvBqvcJqiptilWSmm6XSjmSyoprvmzGs2tLFc0tHmsXrvrpKmVayrCWiqtbQFamKn+OO5hoxrh9YJnmsnJoKnCqMlDef19t3Jaiqyrqmb1MKqisEdl9ZYcrKrFVWfosFNQlNdUmVfFV+KcJVZlJUfXR4wTVREXpTatXIo25LlTgiOQ1QBvbknLjjjhpLZPTaKqzkgxYrtqF2ivZa097OYT8FFVMrd2ri/2dvNeBW+VEswXNvYIwH1y1cI6kBEskq8uKamTUpYJYl6qDmmJaICjZhsr819YTkV38GtGVVuU4dx+1E7XvFXVQCbU/lHdTs1+Oi/tnvlYHigJofbG/I/v3mZQznEVoiq/SuFfVpZVxL71XNKVoTZlc6jft3Rtrc0JREZTGvuYdRVSXp+4UM7tSTe1SqVaK09ZkbU1JpTVU2Yeoa4Cg3k5EZIQ+1tZkba2sLfQ3hlmgdPAsQVXbFZpYHTeqy6aZq49re04xsosyEOljW86wuzixXkqaVPutJIzfbvqX6DnavQuktlX3KMp6rM3/5qC/j7X8tDEorf1R7fk3Ek7YAQAAAAAAAAAAAADQQ+CDHQAAAAAAAAAAAAAAPQQ+2AEAAAAAAAAAAAAA0EN07MOO+ziLXT9mzEad2zK7PhS43S+3DXftxC0fUOwyzTsZ8vyYbzrXL4bh+bPyuT6RkkJ2n+unj/us4b4SXH8a3E9GFGcN02bzzKuofDZNisz/XpO3mX0fbzNepqRoZ859PcUl5kvO8SfBfQhF3G9Em88+fxq3vrwe/DOxW4+I+ULL1VidHN8Vlg8cZzzy/uE+qlx/VdzfCffDE9bt+3gdud8Nt9+aQ1llkj7W9zm7kma642kHAAAAAAAAAACAFyE4YQcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHdvmcfM/1xSQSwHz62a/bavIzR+5CaIJ7Psiw21seRrbzpJL/2rS7FYZmLlsrmabKkbNLI+6k1/KTCHjcnadn7LvM1FWRk32mdfFMrksOGa67JqbhXLz0x35sTKw9mzrK1YmLpFsck59mU0rlymOHNNUzUyXE1lmpizvutP3DX+7tOXNqt/WZsz8NmGmzXHZGT85VnbW0JHbZnVuDs3NjZ0y7Z3ZjQ/2ZRVOEjvD6phjbz1LcM2SOUHiD3fndsdxXfxTgibBHglS26pUuVIGTf7cHY+tMjTl8rmm9Va6uj9cm29a2bnJuBWekxsjbMjl4+4SOFp/SGm6xXVhwIkH5LjaktgbHk3LDRi4PiF4OUr+Oo+O98uFmC0oc0UcU/7mJSIiI83J53jWrqTbOWSUnVMo1VlYI4na3XhwUmGt0fY8aZsPDhYnzHN3D2ChRQltqK1p2ruEhGSp0ubSmktE1JgnlyOeLxSkIXd+WFPWhmH/oJ7XV/WGzzrkphT3u2kkJ9LmGHdzY4Ur7xVpH6IRKu9l0yePq6Qkx+WEhspV5HJEdaVeSrtLqHsAYe0wyjzX2kmaz9r6qq7xwqO0drDc7jhoa0BjkX/BDivyJi+sKXvXnP9Zpq5sGmcJ6r68m3e20p/djHkNKT9tjIrvcnqOdUjIU50PCtLvDe03lPa+7CY/ta+6qJe21kjjTNpnEhHFZWX+D3cx//vlzk8Vt1bRlNi4YppOwQk7AAAAAAAAAAAAAAB6CHywAwAAAAAAAAAAAACgh+jYJJYfeQ5cBVV2AtA6Ju6cQrRMZ/nxeefoOzf1sNRkXfVX/rlRMZ3lBxGto5vO8c+Um2o27Thu6hrmZZNTfgyVm2m4ZcoJpy3do6XcFM3qA7eOVr1YuRUFVX7ddh87Xm4dra26nSrXUSpfzrIOkRWCrTHilI+3rav+ys1gef8kjrlabnFWkLieVTKu2kda+RFXw0xi0357QP7Ovk+1rhcWp1vXv9y+xLrvN6FiowcAAAAAAAAAAIAXPThhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA/RsQ+7XEXwLUaOXzTm/sv1x8Z9ofHrkOT8dNniLC5kvs/a/MDFrOyB4nMtkn3TGSHO9Z9mcn7favkp+z4uMc2lo9t83dX8dXQJjD8uzdvtx32/pQXBT51TPk2ymfuLC5g/O9cnnuXDri77JeR9xf3bGUeGvskknHmdiBzpZ+7Pr89+2KJ5k63rvfsnWtfb63anrnt2QZbHdlZhx8/hM1PDrevNlcHW9VOb5ln35Sdm53fyqC7HSTLcTc1dXyC3Q9Twj+ewKc8Be+w4ccLc0WTqg1Ree+rz5biw4Q8vjsnP4nOiLT+pXorMOl8bXeKSPy4teIOJSF8DJN+V3Odme5y2lvnDNZn6Zp/ckfX5iRh3yMEbvOGPPLOXmMZsLIpxuUmhHBP9Ypq5gBH6Jikq80Tw40okjzf3vdIpUjr3/dNJGYiIkrwcl0b+h0XCO/q5niUtk4kyX9ucvjJM5A9PhXAivZ1Cca3uLj9pL+PuAaw4ZW2Ih+WBtnDJhDd8fLIs57dZjqMxf6c81VjgDZ91aO8cYU4o21YKE2198Mfpc3bmcyzscg3Q3pepVHYjZ6iVw/XznWWozAllb6PFSWjli4S5ru3JtH6UkNYuIqJYmZZxv1yOw17q3wOs3z7PG05EVFk3JMZFVaFxpfDZhDKX1bhuHiW9s3fxc7Tf1e5vPI62F5HWDW09UdtPeFbXc1xs2y73KFKcUqduyi7trYj09TjukwtSml/zhg/2+cOJiLaH8n4+if2FT4V90kyYAysIAAAAAAAAAAAAAABzB3ywAwAAAAAAAAAAAACgh+jYJDbPTGLdY45xHzNPZNZC7hH5Zj87zsguc1X3qKBgWqmZw3ATTveoNTuuGbIjn4lzvJIf63SP3VpHNAMhnIjiEnusZTmlPIsd43ePlkpx7n3cTJm3mXuElB8p19pWinP7lJujWiYwTn68j7m5o2YSy9vWPanLj+AHztlk3ncmYs8q2A8bLmZHXgfzmb3nVNM2eeMmSUGd/eGYiD79FDN7YYWIxuxpFlW6tOsCAAAAAAAAAADAiwKcsAMAAAAAAAAAAAAAoIfABzsAAAAAAAAAAAAAAHqIjk1iLSVOx6LPNmNkppmOGaOkJuuabYYhV3XNwiNFWVDDVjzl5phORVj5XIUzy2yXF0oWDKSIqUW6SmqieavzCZXHaYpLXBXSKCasPM4yHXX7iqu/MkvS0FHO5Ep/VvlcldgOFaFsk12mYuuoQyV5xayUFYObaA8MV63blvaNt66n46zCoxVbASapZQ+P2Nh0TVuLT2aNzeurqavOJjRlT1eNeCfcXN5FU1kqTPrDtTLsarpVYJJUrLpViJLayXShBEtElHShEqt1VizMbUXQSV/LJaU/bcBo//Q0IstVvmLkGW/4+m2yQlzdKCqxgrl7oCiizhYiRclYUiXWFN20OdRNft2omGnjMCeLhKmKpdJY1BQOu2knaR5raYhktWVNaVVTfOV7Pjs/ZbzI2ZHk+0RSIX2uuKAoP22vAf+LphHLnTVlZDnK3Ji/4c3U3Pi3cU3ZWRrf0vggIkojZYwIcyzQ+lofWH4UZcSoIZc9UtaH5xjg/mJonlKENtSUnaU9GZG9L7bSFOQ0+v7F34bqmtyNSqzSRtI7g4goHZAXsNfMf8IbPtU4REwzHcoqsdJa2fZ7cxaiKrsL/dnVnFRQ54mmmtxF86vjV9uLSGtKlz9fxHesOv+V/JS5IqbRtjzKGiqi/YSXVGK1PYDSFlo7JcK8bCp7gEDpfJPzDxptbe2UubGLAAAAAAAAAAAAAABgjoAPdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA/RuQ875vPA9cfDbfa57XHi5M7tiC0TYMe0l/sn4z7nXPvvMJHjpOdaD3OeGxeZzzTX9xurF7fVz0/JD+b2764/nCDxO5Djfu92xGWX3Eec659CKrvq24X7puvStj6qsbKzcWDVz4njdXL96Zgwa+iI+f1zTcYtG3cnjteL3zdYsp3JLSttb13XWUEeG1tIEjy/Np8/3IUf717ns7jmKwgAAAAAAAAAAAAAJ+wAAAAAAAAAAAAAAOgh8MEOAAAAAAAAAAAAAIAeonPjPG7G2GYu6jczjar2fQVm4pivyOas3ISVy0hzk1AiR3JZM4ll5eMmmIkjs8tlwdtkhVn+UT37I1e3HyzJL4dN126TX/vLR2SbBKckl8+qFzNfduvIn6tKQgsjoy2c15fZ1UZ1+7lNK51cX6vvm9l9uZrbzv7ytcWxMpVyti33/Nx063p5YUvr+okR2yR26+igN2+37EmJlYE/qmDfF/d3aX+8h1El3QVZb9cUnJOfltuBm0Pbz5HzM5Esmy2O57ycRntWcbscmav6w6U6EenjOS75I/l4a0vTJ9crLvvDpTYiIgqKcpzUhjnFHF8bF3ze28+R0zQG5bgwktv9x5v294Y3G3JjpGU5v1jo46j2/CXd9zSh666Bx7nvtw7grgs6xSjNqLWwOJdTIZzaXX9wtLaQ1kKt7Nr8l+Zl3DfzNDvSCeVTyhA15MKHdX94rqqkaYpR4l4uLfjDiYgSJS6I5E4uCC+14bK8QE2U5MXG1IRNlTLOZhNRXZnnUncrddf2FFJ+qbJvDYJdu85q61qusksfpc5Z6R0rvcuJiJLizPcA0tpARBSkcn75SX+cmRCTtLv/sRL6g7U9QHNAjsv3ywvOxsaQN7zSlB9m8vKgTgv+Aeq6CZqNaGO+mz27ShdzWf1dKC3NOfk52js71PYvXdRZ+nZAJK952ntP+w2QCPt5rf0CZR13f+/vRP3NqOQnlUNzJ6V9z9Ce1az65/m00vlGiQuK/oclyvrZKThhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BAdm8RyE6ZmvxMpnPRzTVilI9DukVnLFIXl7R5d5cccrePk7lFabqKimJ9y4rKjwsrqzM1hwm12On6Enh+Z1Y7WctpNXQPvtZsfNxfhR+HdY+LWkXLW8JqSKa+veyw+YUfrc5UsLnLMZILY3y6Jc9Q/ZUd1uamNe6SVH39tOz7LLbSZed2mCduU5RdD+7Su3zH8aOv6qXmPWvf9enhx63qsmj04jewHN1n/cHOvIHHqmJ/9R+MBAAAAAAAAAACw+8AJOwAAAAAAAAAAAAAAegh8sAMAAAAAAAAAAAAAoIfABzsAAAAAAAAAAAAAAHqIjn3YaVLqHC77nqvYvrpyLE6TUrak1BXfb9yPGffblhTsRGGc/c3zTiMnc+4vz5FL5n7SuM891w8elzHmftdcyWFJZtht58ZQVqj6PO6bznX8x8rAfM415tna06aQpQsagTeciIgKWQGDSlaoIHb8CLL6cr9/Uc2+L1dlfaDIuVv1Z/72mgOuH7jsOinJeXB/eZVnbYd+35s4tHX9psmFWXrHQWCcZp0flLIMwwFbs7q/P3P02IyzQlS3l637ookOJ1OPoUljB4LEea4m++vj60H7s/xx2rrhznuOKBPehXQ8keyPk4goagry9kKdiPR6NYb9cdP7yPnFQ4qeesnfkWFB1qlP6/KYDSf8r5HCuPzvQdzfZVt+QttKUvRERPX5clskStmf2TDfGx7k5cGem18T44KF/nLUJpTCzxJcX7NWnDB01DVDmQ8kREnzmIgoUeKksmv5aXGBmXnZNTR/uknJP1fqI9r8Vxp+qOkN7h+Ux3W9Lhewtr3kDc+PyfMuNyXPf2lt1dooLSprayx35GTTX/aBQt0bTkRUWlAV42o5/zwPlDVoNhEqrxU5jdw3Wn7i2qG8sy0fzW6c1AXab4xQeU91UXZtPWz7PcJw9787qewlt21zWH6fm0F/4UsD8sZGW/Kmt/R5w+PNyhowLecn/j5S+rc5pKyHyvr1vSdfJmcqUFggr5XRYn/h61Wl8LOESNmzi/OhS5fdot93Zb5q3ylcf+mtcG1rpq0N2vyP/QlDeUrqexuhjM1BuYC1Bcp8WOzfA+RKcqXimjyHwjF/XH5SrpTr554jzX91v5brcqAJ+wOjCA/kC3I75fL+Tq4Hz3/+44QdAAAAAAAAAAAAAAA9BD7YAQAAAAAAAAAAAADQQ3RsEmuZhDrHFYMkO4oYspOWkXPqkh+Nt8xF3c+G7CQiP5WYCkdad9yXxWnHzq1nuRaxLF3knHjmJj9W/k4e/Ai9CVm7KGYBdnq7MbiZX3VpVojhZeNiHmOjmeln5BxxLZWyTuFH3BcPTVn3zStWWtfPTg+1riertglJdTqzHW5WsuEU1+yzyekEM5et8w62y86PDKfstsS2KrVMguN+OxOT95tU5yactm1kR1QfS/ZqXZeH7c6P2ZHZPGvPvpJtPnDcPuuy8rGz2feE+1n3TSf9BAAAAAAAAAAAACCBE3YAAAAAAAAAAAAAAPQQ+GAHAAAAAAAAAAAAAEAP0bFJLCd0TF25uWjIzGNdWSGu0MrNaF0FVa6YyE1CuRLsjoTZJVdmTBxlJ0vsgykxuSIgvOw5RwjMMOtHrlbm5sFNbrliTeQIh0hqMa5yXiAolfQXbXPMoWJmxtnH4gby9n0HDG1tXQ/msjSvG/yVdd/hhdHW9X/VlrauH64us+77+fg+resnty9oXU9O2TasjXLWaNE4u3aVYpi6LLMoprjPbpfGImaaurBCEtWpTF4n2GZL7eSZiWywPTPtrc+3p4UZyQb8goWTreu9Byes+9616K7W9SsLmenwDUOPW/d9rnSCWN5ephuVWC2NhqSY1izL/8YQ+4XK9HIoluqaIplU3x1x/rJrOoGaub+kEJXsI8ssHX/gE2LcHy2+xxv+xj45v8TIHfm2dW/wht/7ywPENLnt8qtH6qu4Ty6DKcpx4biibtX0t3s8JHfwkQeuE+P+4SV3eMM/tMnfRrMJRTRLFlPTPEFocUKGktIbUfs+ohN0ZTblWcrOSVI5NpoqrtK24vwvy/ntc+AWMe7GQ77kDV+RH/CGPxdnPe4f2//z6H5iGhPKi6upKo0h5qdEVuWBsWHbiDd83/nbxTQHLZbbdmLYrzr77PYhb/hsQ3vviWm0PYC6PvgjjaKmGguKykREzT5/nLZuaGWPGnLhXZc62cPk/NQ1oOAPbyySO+TwQ9aLcX+69Ife8P/T51ePJCLanMiyru968gxv+ANr9xPT5LYp72VBhFHrqzQvN24wJq839Wl/OcIRWTH31SueFOPeueQub/i/jR0hppktuL/9ObIycpfqncJ80PYhmqqztJ+XVNiJdGVyTSU6qglrl5JGG9tJ2V/GhqIUX37ZmBj39SM+5w0/QNkDjKeyOvofPnKWN/zXT+wtpsltk+ekOM66/L2WKr8Pgrw/TlOCHSjLv5Xy7see3zIWlr3hMwEn7AAAAAAAAAAAAAAA6CHwwQ4AAAAAAAAAAAAAgB4CH+wAAAAAAAAAAAAAAOghOvZhFzGb4jC2DYm5vynuf84Ett0199sWVRWbYhYl+Xojsm2+E/as2DEV5mXifvRcG3Sj+LcjobjtvqeYbz5ef9fXHXs29+fn+s0J2H2lZ7IKP12ab903csDTresT9sr8V72y7ynrvpPLmV+LvXOaz5os7q0D4yx43Lrr+vxY6/rrzcxHQ+o0YDXMnHDE9ew7cdRwvhlzF4i8fx0/PtFA1jCLBm3fGkGQZbIxzfJPQzuTkPkZ4WMucnzoNPuzPAaKme36QQObrfsWCU4NDijY9w0WZft3AAAAAAAAAAAAAJywAwAAAAAAAAAAAACgh8AHOwAAAAAAAAAAAAAAeoiOTWK5vLEm7c5NF5OCay6afR8sMUl0V86YmycmzOS0MWTnx5+Vq7AIR/rXsLInTPbZlQE2yudLXiaerq0tmCkol7NOU9cmNosLuOmsU/aImfDmp5nZ7xa78I/0L2pd9+UyOfLLF91n3dcXamawM+fEvsda1z8uH9S6Th0b4G1RZqe8bSozj00aTruwdg5SuV0SZko7UbNNXXNRlkkSs051h6Ok5q1IR+fCLO+lxTEr7t+mX9q6nkpKreun6yPWfZN1x753tqC0izR3NKly12zaihPSadLd2vyV4ri5vEtjSM5PHDtEVN4iNFRFTqRJ1Uvy8aYiL99vmP9LMe6NfTM3yY4CuXEvX/pNb/hbN/+JmGa6OijGhU1/Y5icpukuN2AQK3GSZwblUYM5uf0kNwOJ1sGzBaUK0nyNZM8XZEJlPkjribJjad9vZEjrhutqgdMcUAaB0hbF7f5IaR4TkTreJNKy3LifedmXxbgV+V27B7hq39u94b+35f8T01TH5Y5MpGpp4y+vNKDyXmjU/OUYr5e84URE+5dGxbiRQsUbPt0oeMNnG647HItdvcQFwntAGwfK+hD3+8Obg3KdUqXb8uNyQcpbhTxrM1/ziEhu24K8Bly87Pti3OvLyo84gcWR0IBE9O6lP/SXYfM5YppaXc7PuL8LdoZ3Oca036xSu4eh3LZFZTEfS/q84U9OL5ALMUvgv0fbEKIC7d2m9KfU1+oYUOLUckhl0H6/aMVoc5XVylF51sz3L80RuRR/cuB9YtwBXewBhsOyGHfFfnf4yzB2vphmuikveGHNHyfu14koLSgdXFRcsOW0nvQTKoMpL6wbOW0z3Olzn3cOAAAAAAAAAAAAAACAXQY+2AEAAAAAAAAAAAAA0EPggx0AAAAAAAAAAAAAAD1Exz7suMm+a74bMrv2JvM7kThuQBqDWVyunn0rdG3Sw4T5fmO227qPOeYTzvFXkDJ7cp6f5g8rdXzbmJD53GPlzU/ZhQ/Zs7m9dZvJM0um+dHidbGum/Z9jUrmbGOqmRW+L9y9vlMOK2R27fML063r30zOs+6rcD9zrDHSkt0wQZK1BR9Xbe7nmP+u7eTY4/MOqnG/iYqPAO57sc8uU34g8wlYzmUN/2xj2M7DjLSutzUz/xzrJudb903X54Y/GwAAAAAAAAAAAOwecMIOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoITo2ieUmp6kjPxyxuPw0i3DsQLlscbMcSLdRKkhwFyac/FgxImYi6krPR5lFIzWGWBmGnPzY50tX6j2YX8/uS7Ib082OeSMzCeYmrK45bxgzM10mHe22hWUuzK7Dpt0HQSXLZFvVLyu+O3iyOdW6nowzG+ixqm0PXZvkNqdZ2U3kjhE2zlJeYfu5QZ3FxbZtsylx22F2m2PqymWgLZPnAXsA9pWywTVWy0yAf1zZ37qPyzlvm876oFG3p1mzqthi9zCapLu7JuxEM2NXTdyFR+Vqchn4nHJJBCtk12zfiivLz1LlxQVJ9zSnSLpr/3QiJIsmZc35+yb3F+MuGNqsPGzm3FvbzxueJN39exA3i+dIUu9ERGlZ7pBkKJbjXH8MOynI+d391Aox7sDHXuoNN5uK3nAiIjpajuolwqYSKU09echbe4q2OCHKWvfbnqU9zJ+uOeAN3hE3ok1yuRyFcX+ctmaQEue6+OgkzaJQHvO7mm2pf3FtNuX1SRwvZL+XrfC8sn4OSI1EFJXktjBCP24b7/eGExFNVOSXRhj6y1itzA03GLm6tgcQwhWXL+p7Txjf0tpApK9RuWl/uFa+WNkDNEbkuFxNyFNZ87Q5Ia0dfN/vcs/0QWLc68tr5Yd1wbTrQ+i3GOn9+hxIyYy2Bij7K4qUOCFdIMxlIqKfKHuAO3/t3wME25Q14Hg5qpfo5rWiDoHuhofyMOVRQtkj5TeFtBfdEalEae/6LvIT21D5zbO1OdhFIbpjbWNvb3iq7JPU+grz1ShfrIyyZw9yM++QRkN+2ATJe4BGwf8SajQ7/twmghN2AAAAAAAAAAAAAAD0EPhgBwAAAAAAAAAAAABAD9HxGb2IHYWXzMuIiArT2dHDXM2Oi8t+ZdggsY8/RsKxdtfUlR/Bt47qu6cp2d8RL5NzzjSqsz+c45pJIzsCyU9Ktx3BZ3GWaZxjrsOPzPJjnolrWsj+tNrd/dTK8qs2MpPLx5nJKhHRAXnFBqgLflbfp3U9ydRp09QpIDu6GzQU0zbWFgGzfTDOyX/raLZrDdNk44yZx8bDzjgbyDIxLE0Y2cdnK9NZvUJWpmLePmNdY+0+vTUzic1vtadZubqrz4EDAAAAAAAAAABgLoETdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQnevMBpnfLVfaOUz8Eryh41uM+8Hjcu7ufQGTPg9YXOD4gTOB3xeYKxXPZeBz1ey6vMVJyF2XhXbeaZ5ds1Zra4s6j2MPdorK8+Cu9FzZ4oSpB8dlfxoiW366WssKe/XmN1j3/Z+RX7SujyxubF3vm5N92z0bZ37w/rP6EivuB2OHtq7Xj89vXddYGdpg/WMCx7cfrxerpCuTbbWZ49+Oyzv3zcs6fKjPdqo4UGi0rjdOZBLY9brdCc2pzHngZJp1QsWRik4aWUHy27I8ChOOr0THt+NsIVeV5c8lGe40p2l3y1F8DbDCXX+FDE1yXkrnjh1OUVhfnqscQSy0hTIlLH+XbRn6g/la5vIfj75MjHtk8Q+84S/N94tpPrltfzHui48d6w2vjsnS56Em9y6MC3cNsFAk3fdZuk2MS1xfm79ly7ZBbzgRUX2DvFYWt/rzy1XEJLOGvDb/pe7Uuln550LpSWFTLkM3a0Pq+ozlcXl5cdCeJfa1Nn4VooY/vLhVLt9p//sOMe5nR98y4zL8Jp4S487/2f/nDW9uKnvDiYiihtzuJvT3sSnKDRiV5MU/iuR0jbp/UTZjsqPmtK69F/xxc+VfxsOGMv+Ud6mEUeafuHYo+4ZIK58wDKT5RUSUn5bLlxTFKHl96HIgSPkVt8iNvubB48S45JX+gly+6JdimruqcuE/+tjvesNr2+Q9QFRTGiMQ9lDCPpOIKOiX14D+QXnTHQrPqiq/YerP9olxxVF/n8yFPYDrb74jlDku7htI3x9IuN8IOKGwNpMy/12/+fbDOixUh6TCONxRDv/Dcoo/9G8+cZgYd1h5gzf8rIFnxDR3TO8lxn3m8ZXe8OqEPP8DZQ8QCL8PpN+ZOyKVcRbLg8lI5VAeVQ3lT2e1grB36GLquMyVfQQAAAAAAAAAAAAAAHMCfLADAAAAAAAAAAAAAKCH6Ngklh+FzTnHzrnZGzftcs3aLDNY5aipdbKRp3GOrvLjr2mBlcExw0vZCWVuvlsYt/PjZqrucddmfxaQY+XIVex6cPNeXo/EORnKy8jbgpsNExElrF78SKV7ejZkZhpNZop299MrrPvWTWVmq32sIktKk9Z9I/ns/PZYMzv+vblum4P9ZmJedt9Edl9Sc4YWP9LLTBMC5xhrwO/jVc87FeZxrglNPnvAgoGsHvsObrduS9mzN09m9YobdtnDqezvnGIiwS0o+X2BazatHMEGAAAAAAAAAAAAwAk7AAAAAAAAAAAAAAB6CHywAwAAAAAAAAAAAACgh+jYJJabbbapIOb8ZrCu2aul7BkqEivcepKrqTpqM1wxjpu9pm6tuJUlM0+MHMUbbmaaaKqNHapbWvk5NrbcNFdTP4yY6qzULkRE+SYzsU2yxpggW+2wzsw9uQnnI/lF1n3FXGbb24iz/OqOuWijkimimLol/2rdFzRZHFN6CR2lKK7mlxRllV3LrNZR/zHMjLica7au9+sbte57ZGpx9lzWWaGjRBMyJZ7CmKyWnDBxGK4+mjqiMaZOs5KoLg9USe1NU4FKil2o7WnqrIqCVSRIOhlFuatbRUpJPUpTiVUVsYRmz08qCna/kRUaT6N3e8P7+uSBOTEqK8hGY/7XiCbotKsVtrrNr9Lwd0palV+NeUWZS1KAjmbpnOfkqsr8F8avpn4clzSl0JlLRGrvUWkuFybkNFqfqe9sweWBlkab/65LhZ2Eisra5Nr5YtwBE3/sDR8alGWnx7bJ8z8c88+hfKW7PZSqmC2lachqmSkp8qU1f1w0LXdI2BSjRDU/Sfl2tqG9YyWRQ00pvm2vbmUoBCvzSJ2Xwhqg7Sm0NUBTmBfnsyZyqKwB0vqVU+ZY8pSs0PiFyvHe8C+PHC3nl8gFTMb9yojRlNxIWruL40Jpoygnd34+kh8mKcUnTbnskaKYmxOW0bngCkebX3IiOUpVig+kBaCLMiiodepyD6v97ummHNIeIFL2opVN8jv747TKG35tUX65TVZkWez6hD8umJYXeG3/Ir1MxDFB+m8yI8xxIufbRIf5aeuQyQmDZheMW5ywAwAAAAAAAAAAAACgh8AHOwAAAAAAAAAAAAAAegh8sAMAAAAAAAAAAAAAoIfoyodd6PixMCzOcN9irk028y1m+a9xbHttX3e8DPZ9eeO3FW4zf+Z/87zbnpsFuLb1Ud144xLHTUTAMo0a7MHGvS+75vXSnhukrHyOewX+Ny+Diewb64b5tmL1r5dsg+3pKOs87h8mcHy+hJWswJZvF6dtuT0491ET1RzffqwteH6pcx//1Jw6bZHkszbbWulrXT/dP2Ldt7mS+febnMraJd1m++MoMD8h7hi0isT7kY99pS0AAAAAAAAAAAAAXHDCDgAAAAAAAAAAAACAHgIf7AAAAAAAAAAAAAAA6CE6NokNmNkrpbZ9Z5AKNqcO3HSxOSibn3IJc80E0YTcVDFLw81IiYhMlN3H5cLdvLmprxvHTU6TArerte/jZrCBYh7M66zLufPyyia2KbPiTIpZ+QJHpTlosrKzOpnY7jfDOyvh+dn3cdn7qJ7FJQW7gGHCTaCzuDRv35fmWRlYX5nQtSnmadzxmEWOT2Ymsf+bLrXum5hkZrBT2YNdk2qef22hv6xERCFri8JE4A0najcpny0EXZSb94WLZRbvkAhx+Um5DLmaUg5JaTuV8wtjuXxaW8jP0nTg5fxc8/edpEr5Cjk5rv5syRs+WZJl213TdY4oz65VV/unIqn9EqU/JuVX2bOPLpLTCW0YKmVPC3JfNUb84Ubpj9mCOuYFM/9UqXdcnPn8j+re4OeMC4T5pbo4UFwXaOuGOH6VJNaeoi2hPzhqKEWYUtr9af/8nyjK8z8nzXFqf7+1wptyGmlNIyIK3Hf9zvymlURKnNbuEiYnJ4oLYpQ4LrS2mE1o4567lOkU7h6lLU5Y0rU5q65RrouenSjjQ9urGSk/sn+b2OFaGjlOKqPWFrlpZf6F/sZt1pQ5phA1/eFa+TSkvZL7+4MTT8gTc/tUXowjaV+m9G8QKXuAQX94bi7sAbpZS7W9rbJmSO+IbuaJirZP3dVdtovzC5U9QG5KnsuVoN8fnlcGfSw3fCDsD0JhXSDSx5Lr5qqFMu80pH0+kf3dwkqj7P+0cWE6/qo2c3DCDgAAAAAAAAAAAACAHgIf7AAAAAAAAAAAAAAA6CE6N4lVTiJaRwf5kXnnc6B1JJ1du0df+TF5WzHWLUQWmWNmGdykVsM9Wsuf1XZUn2WZq3LTWdcc05+/e+wyKfrv045h8ji3Pyx1Xktp1VFhZUdXraObbidwM1iWd1t+7G/+3MA5gc7bNikZb7hbDGu8OPXl5oqBe3yWtVMylh2THx+1TX6i6azh8+xosTsuYiasmwxnlQwcZd1ke/asnKIsq5mBAAAAAAAAAAAAAOCEHQAAAAAAAAAAAAAAPQQ+2AEAAAAAAAAAAAAA0EPggx0AAAAAAAAAAAAAAD1E5z7smLx56shTixK3bX7HsoD8dHbdHHT8uzF17sDyfeY8l/u0YzdGHfqmc8sd92cBie3uzPKn1v9s9lzXlxz/m0tWu/LwKfMRl3I1crctjT8udeqYsp7kZXXLx33OJaz9TJ/jPI/nMcEyd+sryLa7fuAkeWdTsDM0XFaayUi7stGWnz6nI3n9o2rm4C5ypacFBWu3TGlfdmN5frV1feheG637avtmjvseWby4dd34TZ91X2F8lvqwUyTYu8pOUxDv84ebsLsySM9KlRVQk+dWZcIFH5pBKvvWDFI5vzQ/s3CidpeUdsIOF2yepCDHic9S+lfziSqNM2285Kbl9stVFDl6wWdoPKDU94BpMW7ZwjFv+BOPLRHTzBo6cw1ro0xX673n0Bjyh+dq2vyXC+j6Xt2JOg6VOG0dct99O0mVOenubTjNQSGN0n5pvpvO6jI/YT0xSpo0p8wvof20+R9V5fYLE2VtFcrRHJIflltcFeMKBf+CMr1FeKHNNrrZAyhJtDEszYmoPvN5TkTyfN4N2zHpN5E0ton0/Ybk91jbA2jrq/jO1hZE8YeesuZp+6to5nuKQJnLYU1uXNePtJ2nP1wrezyiOBvfp+ENbkwqnfViRZuuXYypbt7n6pzUjjR1s25o0ytSMhTKoZZP0x0Qfr+YQNsry+WTfr/o652yPygJ79+8sgnQypco9RKylL5tEBEpzURmd7xQfgtO2AEAAAAAAAAAAAAA0EPggx0AAAAAAAAAAAAAAD1ExyaxaZ6ZJzqmXfykND/W6R5r5nGW2WZs5xcwk1t+xDV0ThrzPKxjssrRbQ2eR1yW74vZUX33qDU/Xs3rnzhH2vnx95QfhXVOTUtHSl2TXV52q0zOcc+o7u+fqGzbrI4MVVrXW+J5WRrH5MCErIC8s5wusOpbZKa4BbuAAfubH5k1jp1zWM8K7x6D5nUMWLU0kxrezqFzXDhkJnVxM3vuktKkdd8/Lb23dV05MBusp/zibOu+TT/fSy4IAAAAAAAAAAAAXvTghB0AAAAAAAAAAAAAAD0EPtgBAAAAAAAAAAAAANBDdGwSG5ezb3tRzbEt5MqozMxSU1LjirGu8htXN+L5uSaNluUru88VLOH3RcysNnSEfrgpqascxMvRZGqyuYp9XyC0qKsAxRXjuNJT3O/cJ6i/JkXHLFlQVXJVpKw2ZFnEdbuAzZiZnPZlDWMcJZZ0mCn/FrP7GttL9n3MzJSbwQYFxU6VE8n1DWv2rdwMlve3O37435ZZt2t6zepc25zZSv8g91Lrvi8NPt66Pn9oa+t65V6PWff9y7qFNBuRlMqInkOtSCBXk1WCCmNCGXJyGTRVNIlm38zVGYnsceWSm5JUTjUVVrkcDaEcmpKpuz5Yz5IUmIryXAwURTexWpprAm3aS+kUFajcmCzBqfVVVJNi5GfVmvKzjl7wG2/4U1tH5ELMFrqY46mmfKY9SlIf14aUJsInqTZ2oVJHRGSUdUhSvnTdWHBSJa7Z759gqTJfNQU2EuZ/vk+eKKkrS8+IK8KmR1G+DoqyymIoKMEl03IHB4m8lQ1lUWdR+U5TG01ief6bvFCvWSoM79KNt5kuPdR0lZ+mxCztkZOi0tfKvNRcrEjKo92oYhLJe5umsgdoDivrQ1kooLbGawq8sT9hqjRSMCDLMBZKTW94oyJv8oJReX2I6oqCbN0frr1Pkn65LYYHK97wemn2q8R2s8/XFdWVOGG+igrHRGQ0lVhRuVn5TaF0mVYOOZESpc1/oRxJSdmXK78BXFdULTTlZm1xkKa5todSVOT5NweOtC4QETVqSmcp81/qE1UwW/v9shvf9ThhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA/RsQ877uehzScQs/W1fTfYRsBWnOLbJmxk6Qy7L0ic/PhzucmzkzX/0/JV5tigd+ofpzGUXcdlO1F+mjv0k8vE6xX3sfz6HMNplo7750gGHSNq1rbcNrx/L9uBSz7KbhzbzJxjVezGGOOOs5j/OXJ84wT5rOHDMIsLSraPDNNg34aZbxvj+LkJWB7E88vZ9U2LWX5BYn93jphPCu4XoM2HHfdZyMvq+kpkTVMYyzKs5/qs+9Y8dXzrurL0p63rJyqOz7oO3fYBAAAAAAAAAADgxQlO2AEAAAAAAAAAAAAA0EPggx0AAAAAAAAAAAAAAD1Exyax3BwzzSm2o5YJp2PuyE1YmVlgGNtmllGD263yRPajEqbwHbBPj648slUOZtoapPZzkxK7LttxzcHs7+YwiUQVbjqcXecn7fss88xACCfHTJeV3bjyy9yilZmPzu+3Jcbnl7K/x7YOZMmrtkksb0P+LFcOOoqyv8OQXecdE1aeNze/daWT+SBRbJRNIbsvLtsS0Caf5Z+fzCpiHPl2SXE+dUylQ2YCzi2Cg032jRum92ldf3z977Ib7fxyU93oge95tHkvSZJ3IwNPZJs1c9w52+mzJAn2tOAPJyJqjMi2y0mfHJef8D+Mrw1tKGVvDviflczzS58TEQV5uXxiKVKlf2Ol7Ik/zjWL5/TPq4lxK+Zv84Y3Enne/Hrd3mJcXJM7ORCaMJTV46nweFmMu3Xrq73hOa3vZwn6/PfHpcoOI5CHB+UqctxMy0BElBT94Vr5pDRERM0BeR2K+/1xqbJmBMIcIiIyofAsbUhJaYgoLPgbviCEExGlqVz2WiwsXsp6UuyTJ9jyBf75r/F4/yIxrrGpJMZFNX8Zc9NKf6yT82tG/riS8JxZh/aOVeafmJ38CiOqC2O4S5ci0vrVHPAGExFRY548j9KcHBfV/c/S3ivqftfd7/8W93eKlaYoN1RYFOa65hZI2kQRkZH2Zco6VOpzfStlvHzJs97wSiy/y38ZyHuApCkv5qHQV7mqmKRt78+ZnF7gDe92L9xLuL/pO0qjvGPd31ocaTqYoLPvD21Ir6m8P5yIKJaXejWdNFUCeTq0/xa28hPmv1a+svw+jwaFhUhZg5IprXG7eL8pSaKcf+3K5+U6NevyQHNdb1nFEJbJQEsjxhAZI3Sk5nOtQ+bAEgIAAAAAAAAAAAAAwNwBH+wAAAAAAAAAAAAAAOghOjaJzdVk01TxKLwTnIZCnGvdyVRiudlMmrczlI6kth3bZX9yRdaw6eTHWsPN2yzIjm+/fPkzreuBnG2799CmzCyyMpkdw06etY9k5yeyZ3PTm7bjw7yI7Ohmbtw+c5uUmNkqO076zKhtvxstYplwy2O3yZgJHL9OHDOAJrMpjAtZ4dtM6JhKbMgVY52jufsuycxh+vNZmy/tG7PuK0dZunVT9hH0R7Zk5jG1pzN7B9fMxTATCW6q4JpjcbM5fp9rtsnNIMJGNoDc49H5yTliHgMAAAAAAAAAAIDdAk7YAQAAAAAAAAAAAADQQ+CDHQAAAAAAAAAAAAAAPQQ+2AEAAAAAAAAAAAAA0EN07MMujJmPNMdnHZdm5nGuhDG/Lylm97l+27jfuoj4c938sjwMU/tOHAVvXg5Nijlkz3X9nSWj2QMe7898pi0bGbfuWzgw3bp+upY9jPuY21EQf/ncNrMkx9llUnBu5AnjrKGSqt24jSTrhMMPeKp1zf2+Edm+36Ia881WdzqBKbNbyu6OUzwukcz71xVAHi7UWtfLmN+635/3M+u+oTC77++n32jFpexZXNo+Dl0fdsyvHvNHFzj+9yQXjWFT/jtIWCKnyULH991sQZNnN4Lce5KX/fWp+UkS7F2UQcsvjP3hRESFcfnfM2ru/GM05/szTSO58HlFMr0w5i9HUpcXs8Y8RdJ9pOENT2py+cJJOY77buRo9Z1W3DhWh/z1GszXvOFEREv23i7GbWwsEOOkAZWfkpMUR+W40lZhzMjDZdaQFLS5LMz/4sznJJG93+g0jVq+ghCurCdJWZnjw6kYZ/qFuRcqg2BKmV/Vmf+7aqqsT2kUecOrJDQSEZlU6ceKv+zue5RTdzc6jGS+v76HjTwrphkpVsW4nxf3FuOqGwa94cVRuc2VZUh8twfycJlVJEW5XeR39q712ev6BLZQHqWm66YcyhyLc/64sCEX0N1PcgJhn8L35i5pTq5wKpQviJSBqsznUFijlGlO1VxJjHt6YNgbvnKvx8Q06b5y+X5VXyrGhcI+KpoQk1BhXI4rbp+7Pqq1d6w091Jl3hl1P99ZmTrF9dO+E+2bQFqU4+I+5R0rza9EmUPyll3cPhrhOc+FEcqRNuVGDxry2h8KvwG09VjZUlA87e+U6Vh5/wj7ECKinFQ+atcyaIX7fyZ1gPCsXfAbACfsAAAAAAAAAAAAAADoIfDBDgAAAAAAAAAAAACAHqJjk9iUmba5JrGJdKTUORnIj9Nys1U3P350kB+ZdY/cm0iIc08ksvxyzHLCPWZuPcvJg5vI1p7KzCge3Thg38hNXdkR8jazMV5efhTWOZHOyxhZR+ad/CpZhmkjq3DiFO8Ne/+6df3BRQ+3rt/Td6x137c2vSrLj1nKuPXgR2ETdjw/dUyAeXvydknq9hHcpyayo/ANdpZ6y9CQfV8zM3PbVuu34uJm1pH8CLIZsDs8zmf558ey66RMNqyvImYOEyR2HblJA792x+1cMY8BAAAAAAAAAADA7gEn7AAAAAAAAAAAAAAA6CHwwQ4AAAAAAAAAAAAAgB6iY5NYSx3GVbvg6qXcdNbJnefBzQQ1JSGxDGSru2h5WM8S1FmJiAJucurEcbW7XCYES4GjWsLz50oxoaPKwpVSudmrWyZuSmrVw1GUilgnmDK/z37uryaXtK5v71vfun5o2z7WfWHN39+u4g+vvaQWSUSUFpnab5RdB9P2INn2TGYSu72YmR5/rnmidV8UZg29ZdI2iU1jZawygr6s4RNmUpybdMx+mVpMVGNl1/JO/ddEujJpL6MpRElqkM3+7lQiJbNhTTlKU3uS8gsUZaZIUfPNT8iFF0SHun5WJKgSRorinKQESUREI/5gTSFOm9s5ReFWIo5l+a3Hx/bxhnPFZ5doUJbYK86XFSQb1X5veH5K7t+oLk98UelvDgjHxWW5TVxl9p1o819bm6U1UlszNEU3qXxafur6pKi9maagmKioLOYmlfEmKUFqCmx5RcFSkGdLXQV4Rps6PCMvST4r/Rs3ZEXax2mRN/zZ8SFvOBFRGMprQ60qP0tS7dQUOzWV96ghqAPOETcYzfLMlaJVFUY1zp+fpPZIROoRBE2tUiKqapNMUSyUVGKVNUB7x7r7/U7Q2qmZ95fdKIq+QU1uwFxFmEeasmxD7vxnmgu94XdUXH81GeWC0kiKmqaR1LuVBgybcn6RoC45F9aARBb2Fd+X+jt25qqz3aptdlM+7T2qxfHfuBz1W4eyp5DGjqjOSkRBIs9XU/HHRcpvFG0uSyrW3e6hEmlKSj+uiCisafsXuRxSnLoHUNppV6jBis/dfVkDAAAAAAAAAAAAAABmCj7YAQAAAAAAAAAAAADQQ+CDHQAAAAAAAAAAAAAAPcQu8WHH7ZRj5uPC9U/Bfdpxf06h4xPIsh1mj3XtvyUb48Axc+blSJg7Ezd9wA2nHf8Zkg15UnQd4bG4viyRa9POfcIUt4Ys3MlOMNl23S4Y9neOFSJy/E78z08Pal3fXzqAZWDnl2/6+9u1Vc9VWJlYe5rILrg1fnjWjil9Kvg53LBlb+s+yUcIERGxtrbuc333TGUDktvnu/6TxL4vuGOE+Szkfgmd/LrxpQIAAAAAAAAAAIAXDzhhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BAzMIllfziWhVz9Ou7zXxMRNYcz28KIyYCXRl27T2bSGPhNJIlsU1duWqmZHPL7mv12HDeLtOrrwkwkA7dM3ARzMLOFHJk3bd03OZ3pY5tx1lCOJLhk9ttmbszLwU1YHXPO3CSrY5wlShbYD+IWsQEz381POn3FzVtDf7hbDn6f26e8fyzJamObwAY1ZsKauOa32b0pM1k2juxzxPLg5tauSWzETLa5KTc5Y4SPVW5e7UpA14YVKfMepjkgl7s+4o9z1wBOVJPjclV/uGtCzUmKcpwkEa9Jd2toEudRdeb/DpIqK3EoZKeVvW2eMuobS/6IgmxmHigy5lKcKn0udQgRhQ1/JwdK55tNcgNqa3lx2l8OrW21thDZjVLvLxSNIbnPGoP+8EQYakT6/I/q/nD3fWE9S5n/SUnoAK1flLiwIbeFESasNqYiJb+oIUR0WT7ZxYM8v6K6Uj6hH7W+0v6pONns78j6s3IHa2tNoTnzskfC+4dI70cj+DDR3luzidp8ueOkua7WXRnD0jjV8nP3xVY6oejaeh5Kc4+IAtfFCi+H9M4R6vRcz5LGqdRGO+KUfWbob0RxnSSiqKrNI3+cum9Q5mUQ+8tXnxgS0wivDCIiKirvGmmvJL2DiNp/I3CkPtH6arbQ7FPee8IWTH0PaO8waex02Y7S2qDtvVX3Rdr0EsZ2qL1HtXe2Mt5klAK+QD9B1bZVOl/av5iku/ZT9y/CPNfmv+U+zY2T5v8u+A2AE3YAAAAAAAAAAAAAAPQQ+GAHAAAAAAAAAAAAAEAP0bFJrGbumDJFVW6W0na8ekl2xrA5lp0ZL47Z504thVGWhXu0lps68eO47pF56zi5cpzWaCdIWTp+vNK45hGsvEklK8hkvmzdltSzuIipmqY5uxD8mDw/IqyZBVhpXCVcdky+yY7tJsNO40Z+M9C2Y/FchJUdOXaPhUrHS92TpdzUkD83cDonVVRief9YR2E7NL9oazN2HDlicaFTeKudGqxP3aPYkvQvAAAAAAAAAAAAAOGEHQAAAAAAAAAAAAAAPQU+2AEAAAAAAAAAAAAA0EPggx0AAAAAAAAAAAAAAD1Exz7skhLz2+b4T2v2Z9eN+cwZmOMzLK1mCS3ZXte3mPFftz13iPt+Y88p2g7UclPZd0nuB8/1s8almE3k+Cfj1WJFd+WbcxXugy0rsHH89FEhy7/J2iwpu/7NsgIXxlmoIwEv+d/LTxvnvuxGLj0fTjt+BHkdWV+1SRaz+1Lmv7BNop77fuMS1Y7cuuSbr00anPssDO06cj97ESuHW3bLRx73P1ez88vVs7952d38eJvx8Zjk7c6JqrtA33kPUNlL9r1X30vQYFd8RpafkR0xStLYmu9GSbadyONPc+dzJOl40mXCNdrG/m/RJM7jfkXiXJCIz0/L+RW3y3H5iv/faZoDchqt3dvm5m9Rul5MoxG4/kIZOUW2vVwToyiq+9vd9WNplUPzgyrUq5v69hq1hXJcfaEwkZSlrrhVHlShtJwo4zApyA+Ly9L8l8eN9Z5qS6hECWXXnqWtQ4FQjm7LJ0V2UwYiZa1W1jttLZTy43urtriqnJ/kP3dHnDAutPoqY1qc/8q4nU3UFsmVb4z4Oy5U3qOFcXlhlNZgbQ2I++TySX2jjQ/p3dst3Id027OEfQOR44fbyk+ur/YsaQ3QyqDlp60dIso7MRTWymhCTiO1EdFzrA+Nme8N1Tht4zPLifvkOP77r1O0dmzzD99BGg3p94G2ZqTF7n6rSetGVJPnUKTNPeF9tKvHmrZP7eY3QLCL971afbXfB9p+Xlr/pb0B0XPsvYRk2r6hU+bAzwgAAAAAAAAAAAAAAOYO+GAHAAAAAAAAAAAAAEAP0bFJbH1+dp7PPUKazMvOB/bPy84eT28r2w/bmp1JjZgJU1JyHsZOjUbsKLN7FNY+as/MY538UmYqYx1xdT9Xxspx1Sq3EWXhznFKfvTaMrF1ntUcyq6TPnbOM7DLwI9RRs3sD9N2JJOZurKjv26bBaydeB8UxuRvt9zk1DVzMazoad5vorwjjtWrQysD63i+c5yUt23buODmtywP9+g777uwqZkWsGJoR4a5lXfU3dFnAAAAAAAAAAAAAJywAwAAAAAAAAAAAACgh8AHOwAAAAAAAAAAAAAAeoiOTWK5imEy35bcGBjJ7EAXDmTShZUJ2zaVmwJapqOOiSA3Aw2T7I/AUQEqTDCz2iIzP3WlSdifJs9tOJ3ndqqsxsqnKYVa9XBVXQU12fyUXYg8V0Xiz3J6LoyZ2WrI8nYtPVke3HQ0clSULNPPgLetkx//m5fP6QJuLsvbzFWeSnOswCyuTdGXtaerKCgpubp9kKt1KNsiKBW7bWGZLzOFmcA1I1bMZXsZUQmWiAaX+uW7JjYOimlUFUFB0Skp+MOJiBJF0SkZkKQMlTJU5X/P0BTJIkGxNFeR02jqR1I6TW1YUzFKJZNsRQUuKYtRsjKi0r+JoswlKXrqKpGaOwP5WdIaoLVfVyqRc+CfxjQ1NRrwN5hpyBVPc1qcvz81dVFNpS7tEyaYprImqCkTPYfao+BaQ1OIUxUihTjNjYOGpFabdKs620UxTE5xQSGUT5uTugqc/CxRIU5QjiTqTiVaGs+zjVR5/5qSv2GSvPJeUeZEILmoUdZSvs9sixOU4k2ovOcjbbGXo6Q4dZ5rasaSkqmmmqgoyIoqsYqStabOK6YR9nFERInwnicicb3JTXfnaiZS9vo5SSlaUSOVVMyJPL+RWhnKaWYLzUFlfikq7RKaCrP0vlSVZZW1IRHmv7YXNcp6Eijq19I818aotjZI7z5VJXbm01+d4+qjRHV0pW27+P2nz0llLHWxtqp9Fc/8vQCVWAAAAAAAAAAAAAAA5hj4YAcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHfuw47bmQdE2JD5g/miWITPuXx8usO5LmEs7bovs2mHHzH6Z+/7Q/JRYvuOc/Cy7bMv/nOJUwPmUaflcYQ8zjs039/HBy6S5wshPZje6/qq4/xX+LM0nimXv7vrps3zYZXkXx+z7uE16UsqeFdtuCa36crvzNn8hxn8dGPu+pN9vKR/U7Q4pbs/+DqruzeyS+fFosyE3/vu4D0A3P8s/hXsba3du497m5xCfyQEAAAAAAAAAAKCATwcAAAAAAAAAAAAAAPQQ+GAHAAAAAAAAAAAAAEAP0bFJbHE0s/+rUdmKe7C+rHUdhMzOcMrW5k2K3KyUx9i2hVx+2TBpZ9e0kN/H83ZNDkMmDx9w6V/XXJTd58o5c3NPLr+cOi3Y8RdQ9mxuqumWnUsf8zhXipibGFvmwZpyuiKRzNvasPrm3D7gZqWsbWPXspWVifdVMmAXojCS6S8XCpmNaWW6aN3XSLK/S3W51bl5a+r2KTOxztVYUR0zXcv8mNcjb49bni5gebuS8kmBZiXRlNzOE5sH/BGKFnisyalHfpNvtw85kjk1EZHJC3HK/EiVuDBRZnrNH6xKi6tx/oJIUu9EJMq2E8km2epaoT1LeIukyjhPXJN5hhny+z5oFmTN+fyE8ipT2kKqc6B0fqism9p4mvUoc9nUhL5R2sPk5bhUaOOkIGcYD8gdEw01vOFpLM/jVClg4M+OiGz3IVYaZdxo7j6kdO5+yEKby0JXaeuJ5sZBitP6SlurpUkZNuU5zvd4LmlDcR8iPEvrq6g580meaj5RZhGhMu6Dpn8gmJLcmElJHlih1G/KWEyLSjsP+idZUpTfK2ZajguEeU4kv8+1OaaNOXE+a/NcmWJhQ0holLmivGKTohCuvOeb87QfIEI69wcXIzfduYsj61FCO3G3Nu1xSn7Gn84ESvlmCUYZA6n0ulQ3lt0UQomSp6s4Fk1R29jIUWEiFz4Q3kfqb+4u4rR9qroXFZdWuU5a20rJlOlKSUn5vSbsHYKqPJG13yja/kqK63b+kzD/dwU4YQcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHZvE8iPeeffo8ZbM9slW0XRMC9lxdW4ulTjHPS2FUm7q6hzJTPqyI5XWsdbQfi431zF9XJ5Wvs89TiqZXLinfdVj7YyIHcPUjnLy9uTHMNvS8Pt4GdzTmdy6k+XRZorLmkJTPA0MNzkVHuTkb5k1Okfw40bkvU6n7fPWvLhtSr1sVPMyJUX7WblqVo6Q2famjjlmwOJyvA+cvuamMlEtayj3aG2gHKUGAAAAAAAAAAAAwAk7AAAAAAAAAAAAAAB6CHywAwAAAAAAAAAAAACgh8AHOwAAAAAAAAAAAAAAeoiOfdhxX2iu/7T8ZOaTi7skS8r2fdznXHmfqdZ1mtrfDWujWcL8NuZ/zv28aPzXQd52tGZSXiju7I1EIkc+OD+Z/Z0wyeG47PjBG2D+3tizclXXLxp7Fitu1LDLwSWHub+8Nn9+hSx/LvXs+pzj6eIy6zenLfizLIl61yee1AeuLz/rPtYWOaevkqwghvkNDCt2AS2fgm3+Btk1a782KXv2Z5rzj2Ei2ycgb9uo5vqm8/vEc9HkonuZwrgiYy7od8d9cl0lmXUiWULcREqavNKuOSFO8E35XM9KBNlxIqKg7A/XZOCjmhgll6Eox6UF+Vm2r8nO0GTME6GvuP/RtjIMKhnG/oU5mpJ15d11znqW8pZre6d0gjLMwqY/MtiNUu8vFLmK4nsz8PeNNse1OeSuwTtJlTRUlh3IFgr+8dZUtkBxQR5UJlTWjdA/qMK6N3hHmpwyX8Vqaf0hR0nzv9t5IsUlJTlNNNQQ44rFpje8Gg/I+VXltSHU1jtp3e3SzWwgvPdDaUDPMsK68g6b9g+EWHtna2NOeGdLewMtDRFRlPfP51TpG5OXB77ur3oX97dQDG1Yae0kFU97jxotTshPW//zI/KmJxDyi6flSrk+qjlpVYwSy661hbqHF6IC1+H5LEQb89IeUX1Xau8p4V2vzn/lN4AR5r/r854T1JU9p7KfF7taWxa6iDPSRCGiQNuodoO21kjrk7a/VtcnYR/dxfjbkU7pY2FYaPOffwdoYzdOc5ywAwAAAAAAAAAAAACgh8AHOwAAAAAAAAAAAAAAeojOTWIZoXMssclMH/iRdO04ZI7ZgTYck9iQmaNGNWaq6B6t5+dpuZVl0T4bmevPzC+qk8yOrGafyQyY6WzgmMoFzErDsPrGw3ZjhAPZjUkla96waTd1yJ7Fj3K2Hd3klp+smVzzFcvMhR2TdY918vsaw6yvnOOp3PSBP9c9dhoz8z/eHcYxQ0nZUeWkP2uzNvPlalYx3gdhUzPHdAL430a+z0RZnrw9o7rdB+Lxd80iKeFt69yoHacFAAAAAAAAAADAix6csAMAAAAAAAAAAAAAoIfABzsAAAAAAAAAAAAAAHqIjk1iuTlh4pg7NuZlJo5mgJmI1uzvgdzkdGJzpvgVNO37CpOCSaerBtpgZptpZtPZzBWs+6LBTJ6t0JeZrMaOOWY6nTWHq9rG/7aUqBwluTxTo6s3sjJFjkpsfopfM1VX1+qXmaqqSm2sJ7nZq6uqwuN43q4JsGWmy6roliFlTW2p5/Y76rl9WUEGFk63rnOh3X5jSTYuDH/YTES3WLK4j5U179Rxu6Do5pjAckUYS03WNXUVlP7a+jQ/k8r0EN1Y8moKcdp4FtSAVLG9nCzrE0T+ONOQl8Cw3t2/Z7hjP3uYnEYz+ZYk01JFZakpCyqK6kf5aX+4lobINou3yjAsSzoNLpAfNrnJX/icovSmKURpyCpbiqrUHFB87QZVhUsaH4pqo6b4aiJh7in5USrPoXrNLxWaNpRJpChIqwiqc23vCx6nPUpoClXtuRuV2C5UJbX8NMVOta/q/gwDbY3sckp2o26nxYmKcy+GNUNaAzR1UUWhMRX2U5qyLElKkETiJDMNuUM1VVxNJVJWuReTqPNZXDu0eam0k6Riqakw6uq8Qriyxqep3O5JzZ9hrss1WVPTlCU9tQy17IT1XyvDLEEbH+L63KWqcyqpRGtK8YqyeyC9l5V5rK1d2hiQ3hHqO7aL97mqVK28Y8UkWl9p78Qu1jt1Dglrsvo7qds9wCyaljhhBwAAAAAAAAAAAABAD4EPdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA/RsQ87bh/s+ung/smW7L29db11+6B1X7Kl1LouPZ0ZbLt22PzvuI/5Dys6RsrM9pj7iDMF23A6LmV/Dw5kjpAWLbT9KD2xaWFW1tj+lplW2LO50bNja13fljl04jb9bpuFgu256seCPdaEgRinwe3QuT14ruKUr86ume8i146d9xW3V48W1az7DliypXW9fGBb63r91HzrvrFN9piRCBv+5xIRJcyvHndP4bat6L/GyS/NSTfK5UsLrENmkY08AAAAAAAAAAAA9jw4YQcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHZvEcqnqwJULZrLIjTizJ0xduWQmq8wlmwPHBJGbJCbMDNbkjXMfy4ObsDrS37wcsSIl3lZeoUzcRJSm7fzChiAd79QxLvG/sjRJ0UknFNc1seXmnpZKuWO2GTFLVS7FHjbt+9y/s8ydP1lb5JhZspu8L5fZsOZZ4ZuujjTru4DZ+RpHkjtXyRqGm8fuSMeuO5SpT1lbxCWn0Vl+UTP7I2w645ElM1HgDSciCuMu9af3MJq5dnPY39DhkDSQiMz2ghgXxMI8cs3i+bNKcmdHOX9cPCVXKqzL64Fm5ZzmhTIq/zySKisxn2McVTJdQyi8lp8q6S6VvZQKEUSlvFApIpqKJRP0ztbn9jiltwKhrwI5jbtkdZJMesxsQnO7EPf7+zoYanjDiYhMTRn0zS4aTCmfkd7tDXlgS2sQkb33aEPKsothuONhUhnkJIm8tFJa9Id36lajLV3oL6C7R+Ek00rfCwXJaetxl/NLWtfSnPysUF661HVyLtDmlobHlYQ46X1IRNRUGkzqGyW/bvYAibKx0cawNO53xPnDk6IyruSlUnaho0wj97cERyqfuO9/DpKC0BbaGjAuL1Jh1V/AqOYN3pFG2evz368uRnhpa/2b5me+FknPmSuIa7DSL9qeWNxXKu/eMK8NAuE5ibahk6PU/by4Ril7Cq0thCJqv2/VtUsqhlIGdU8hzX9lDpHyvUWql1Yndf+n/AaQ9nLqPt/9BmbF7b7N/hzfXgAAAAAAAAAAAAAAMLvABzsAAAAAAAAAAAAAAHoIfLADAAAAAAAAAAAAAKCH6NiHHce1tQ6YH4qJyb7svomCcx/z68XcRjTLji+wgmCorNoos9scE+K0mlVzOsicxz1esZ08GOZTIarYlYyYb7qU2zw77i+4T4m0mNXD9V2Rq7C2mJR92HGbbct3ilPHhPnE4zbZhQn7uZYPO2Yn7vrJ4j4fuP236zODt3VUza7rWywnffRzWtq6fqxvYeu60bAzDJlPIV6PNht+9lzXd4U1Ptl9uardaNxOnvuXsP0L2r7q+LPa/NwI49P1WTfXfVkAAAAAAAAAAADg+YETdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA/RsUlsbQEziyzIJqwjQ5XW9dYpx140zuwauWSuyTsmsNzkNGbmg64lIXtuyuWDc47pY5TdVyhmtp/1ql2+3FT2/TKq2g+zTFNZQRLH/pabwZpyZj/pCv3GQdb0/FmuOS8324zq2bUry5wUs4S8f8KGcyPPn0WZNgl4ZrLbqSkyK2tu2k4UR9kDarySbfbLPIq1S+z0B0vmlo//zYeFKxUdNXgku3TMg7lJcMKGTOh87uZjmuftNp8k0d3rxAOyXHU00vCGp0353wRcs3NOGPvDkz65DMODVTEuF/nN7LeOtw18Vgi5fEaRF+em/1Z27lzkaRR5djmRHKWNsabQho0hOY1rdm49SyhHbmveH0FE27YvEOMiof3SvNz3zf7u2jap+cO1NIEiEe8uZ61wRQZ+tpAW5fY3/f4GiyIlTU1ZG6r+uKQsT7x8n38NIiIa7Pd39NhYv5gmdfcvnFCplxQlJ6GwKcdJY1Gb46myrNXnCW2YkwsY1OXxK61r6no3NnNvLNqcVN+pyj9LS+lc1x+cuKi0hZCftn7OJlyXLZy0JIwr5V3p7rM5oTDmEmUdKitrQF/RH7dlsuANJyIyOWUPoMwXI6x7UU2pb6LNMTFKJO6T45qDQqcom311DyCER8oab+pilLj/08qXauuh676Gxwn7ikR5Z+t7eH867XfUbMF1h2XFdVG/QBnz7u+w1nOUNBqR8BuA5Omv/n6R5jgREUluj7rcs4tLaJfvPWnMp1pbaOtdF87VtPd5GAsNpTS5Nv+191YgeWBT5n8gbvK0siuF7xCcsAMAAAAAAAAAAAAAoIfABzsAAAAAAAAAAAAAAHqIjg8yNrgZhXJUcMXIaOt6dNuAFRdOZmcWrSPPimkcP4LrHrkPctnfOWZ+Wi7b58dTdlZ3QX9msrvRDFr3JSE7N+manDIzU378s+2IMDetrGX1jabtG7lKrGVu6xx956YyvM1Sx1onz5RmLXMYpx5N1iWNEWa+6yrz8nowEzXX3I8f8c9PZdc5x9QhqmdtEU/LZ/WLrB78+KtRrJMSR9VVOprttm3Kjq5apmzuyVVeDnbsNnH6npvO8nEhHpEFAAAAAAAAAAAA8IATdgAAAAAAAAAAAAAA9BD4YAcAAAAAAAAAAAAAQA+BD3YAAAAAAAAAAAAAAPQQHfuwS7mUemo7+QormWOvn/3mJa3rYJutEZybZj7DmF+v3JTt40uS9I777fvq7HPjwD7TresjFj9t35dm1dxa629dN+t29YMwq1fs+kVjMsiWjzTXPRmTnOb+3Qrj9o25KvuD+7Bz6h42s+davu6a9n2GyUjHIfNn5/Rw3J9lkl+S+fMrFu0M81HmE3ByOmuMZsXRfR7PHsD91rnP5fUqbmPjwJF25vXifuUaQ/Z93Idf3O84nbP+ZO0e2n3A/dHZPufs/HgZo4bfT537XK4g7rZF8PzVnfcImgx3stWvm52blv9NID8xc99+cZ+cplRoinHFyF/40bJcqbgbnXoiCgWfnKFSX3c+W3FCERVXouo/xZiX1LzhrzvwETHN/2xaJsaNPzHPG54flwvB10YXSd6+bZ7zuD45TpNnDxtCnNa2yvyVJOJz9Vk66RnadAgq/k5LJ+UtRnFMHh+BsAfgfkJdhgf845qI6KR9HvWG/7S0r5hm/bMLxDgTKxNMGFNhs7v5H8T+sWNycn5JUR5v4SJ/Oy2aNymmmar513cioqlNA97w/Jgwkandx20npDm5Tlp9g0R7lj9OWoOI5P4gsvcHdvjsn/9EpK59YdU/J6K63P75cTlOWkvTgpJG2VwdvvAZb/hd4/3ecCKiuKnM87xQQCIiYX3Q2iKsy9lFTaFeyqIstR8RUTLiX2D751e94UREjbq8lsfbhf3fhLIGNMQo8Z2tvYPSghzX9C9Rv32YP1PXT7iVRHg/Ecn7Na0/Zg3aHkAKV343GKVNQmkMKHuAtKj83ij6O43/7ndpTMuDIFB8k4fCPO9mn6/h/rbkNMtyvZrz/A8rLZTnv/JKpNq4f/6HU3IBpXclkTy/tDmkzn+l8NI+StsDmIocFwl7/aDL35McnLADAAAAAAAAAAAAAKCHwAc7AAAAAAAAAAAAAAB6iI5NYjmuGVHEzBtik5lP5irOfcwMyjYzdPJnR8P5sUT3mHSayyLHStmZ5yMPXG/dNxJl5xfvn1rRun5mwraznKyw5ogcs99SVuAol12HznHa+kR2NDSoZsdp244F82TKZ1OeTjsOauXP7jOOGUnSl0W+ap/MROCwoWet+4aj7Gjsdzcd2rp+enzYum866cvyZv3tmovyMcPNY91TovxYK69vPGDXozk/y+S4wx6z4jZVB1vX6x/cp3VdHLULJR15N26hjGCS5ByZTZiphmFWR5FzDDqQzBsAAAAAAAAAAAAACCfsAAAAAAAAAAAAAADoKfDBDgAAAAAAAAAAAACAHqJjk9iAmTTmp+zvfPmJ7LowKSuFchNHy9TTUQThKhtJkZknOpaKPA9Ty+wTH5qyFQ0X5DMF2Q2VERIpZAV0hYO4Geyikansujxt3ffLZEn2xxZmEutYQUqmrqFjLikqxzjhXIUs5Uqmebsi3Kz4pQObW9cXz7/Pum9hlClnHV7OTIx/MHGYdd//zsvaem0jUwhuU8pkxZDUWYlsE1nNdDbsyyKPGXnSivtpsF/rel2UmcQmrpANa2rDraFdtS5uis06MnXUZXi9LDUgRRloNuGqOXOiql9SJycLN1IkCxJZ/WGlUdRFRxW1t1JJ6ARNarUoyzYFkaLCKCgm5RRlofyUkp+kEquomMVluV79/f5O+dxL7hbT3D5flln7y4m3eMPNVMkbTqQrJgVCV2l9nw7K/gJUhTihHInSfqGibperCObzc2AN0JQ9Q0GGS1NFy2nzX/inxDQv/xtjpa5MCOk5yjg0dVkmLBAUMYlkZezCuFwOSVmMSFbZk9bI56K/zy9HedrSh8U0TUUy7fbgld7wqdqwN5yIKKoo81+ob6hIFCYluf3q8xQVwCF/uOvOpdM4I43pOeIFIz+t1F1oF9fljRWn7A+kNouUdahWlaUCQ8GnTC6vKMWLMUTUUBQpBXVU/luprRy1ma8B2sDS1JFLw/414BOvvFVMs66xUIz7x4dP9obHk/LLV+tHWSFYTKKqyNfnK2uAsK/IT8jlK2j9WPU/S5sHswVNHVciVNRUNYy0xw7leRcX5PdUWvKn0/YAgaLsru2HpL2+9nuINBVh4VHafEjk7Tflhv2D8fcP/LmY5tma8LIkonua+/sjtsl7sm72ABraHiApy+liYYnSfu8WBWVpjbCLudOWx/PPAgAAAAAAAAAAAAAAsKvABzsAAAAAAAAAAAAAAHoIfLADAAAAAAAAAAAAAKCH6NgLSnlT9m3P9U3X5hvst7T5J2Pm5VHiDyciivsEv0KOOTT3CxcynzL3PLOfdV/Ebmwm2cMaDefB3OeD45Oryf7eym7bOm4bQMebM2PpEvP34frq4H4OLD8/TtUV83oLySeeZgteYQbwG2K7Uxey6o8lmW+womOIvd/Attb1o/MWt67j0Dauj+MsQ+5bo80/Fx8zrH9dv3Lm2cxA/1Op7T+D+zPMcX9+OdvGvclc7HD799DxacHLyH1vuT7EuG8ruw/s50r+mQAAAAAAAAAAAACIcMIOAAAAAAAAAAAAAICeAh/sAAAAAAAAAAAAAADoITo2iS1uz8z6GkO2yaBl0sqjHHPHQDFx5HBTQ8t80Pm82BzIMkyLmQ3i5NZ+676gnhXQ5JitomNvys1q2yTH2Z9xtS9L07DvK49nf+eqWXjkSLZzy9IwzuJM6DyX1Zm3hWtKyv/mcs6uSWxYz/LfUBlpXd/Xt8K6b2My2rr+yeSBreuxZp91X8g6tVTObEKnY7uz4kb2d36S1dGRsua1522UcySguWx2s2bbZBtuqip3NyUF//hx+8CwPk4K3MTWKTt/Fqt+4KhNd2rm3GtosvSuWXsLRao80GTMBQnsqCY3Xm1csM0nouaEPy6syDLwUV1+Vqi0RWnUn644JsuO52pynNROiSLprknOT2wc9Ib/5bNHimmmJL8HZM97TnVYLmBUlds9Py2kUd4ZFMj/9lRbIuupJwv9PgOCKfnVWNyijRl/uOlCBr7X0NrfcuvA0FwyaDL3ktsArQyV0T4x7pvpy73h9U1ymuI2eUyFytogjd/CuDL/63Kc1BauaxIrv2ll/o/2e8N/Om+5mGZBUagUESWpVEAxidr3rvuQnRht/DWU98JiuSDpIv/ATSblxg02K/NfeC+I78dZRlRVIqXpor3nFdx9U+sxwlpDRJRsk99Td2/Y3xuu7Rty43LHae/YwoQU3uUaIDwqzSnvFTk7ipv+em2Mh73hRESJcr4jEDpL2+Np/Sit86mSxnVRwzGL5QVncMWkN3z7piExTfCE/DB1nzLL0fbfEuo+X6Htt/DOcGlhIKJoWh6jTRLmuVK+/JScH/8N2mlcpMzxNvdQDHH+K+/RpCj3VX3cvzd/fGqhmGZ7Xd4rxRP+/EoVuQw54T1PJO8btd/ORlkLm0NyJ5sBfyOmeXkPEDaVvaGyRj1fcMIOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoITo2ieVHFN0jv9xail+7J1cDdlTQMhFwTitys4KU3Re7JzIXsYIws1dq2N8hcxPZ3ybi13YBuRmse/SX1z/PDDfd44/8KCw3dXWPf/I4i1Q2ne3UzDKIWT2cvipszzL52ZP7tq4f32YfhQ3DrFPGJ7OGz+Xss6rFQlbAajU7FusekdeOMVvPZeXlZoI51xSDZeea//Bx0hzKbuRKsEREZn7WeaX+bNDVpuzjvQkz3zPjfPw4ZWLjmJsquKaLmpkYAAAAAAAAAAAAAE7YAQAAAAAAAAAAAADQQ+CDHQAAAAAAAAAAAAAAPQQ+2AEAAAAAAAAAAAAA0EN07MOOuI80xx0Zl9OuLc4ceeUnbd9iJeYjTvPjFTbZA1Lmj61h3xdsyhzmWe7ENO1f/py6fR/3hRY6Sr8R80HH/c+5ktXcp51VDM3nHMujze8f/5tdG+dTqwlYhqF8n1WO7ZlztbEpZyjwdKx8ScGucD3I+iCoMV9vTkVyVeb7Teke3n78WpMGTx0fcdy3HPdbZxbbDv3mjUx786ttL1l/B1zCmZXDleHmYyYp8wyccVbpzJ9fr6H1QSIopmsrjObWMBDkyjXJ7Ghi5g9TZdv9w2NHnOtT0Urnf5Yq6S75tFTpbJ1rK8ek63xxB7f975Fd5Ud1fxtGdbl8rm9NTn7K3xba+HPnGKe+SI4bnu/v5DHql5+11d9+RNS2zrforqt6ilSZXm3vmd8SKE3VDW1+QxnSuCYiak74+7O8TZ7/2hgNG3KcNH7z1e7mP/eHytHmg7tX4uRG897wB9N9veFERBQqZZ/0D4zCRHdtmxPayShzPBXeF0Tyu4SIqNDvb6iashyb0Rfn/CfS39lSVOofbjvSKE0pvevdfRcnv10ec7XqkDe8UPMG78hvSu64vLI/kNaAnDKwgkSOM5GwBij9obVTurHkDf+7e08X0wSRUr6xgje8WJPbT93LCXslLY22B0hK8iBsjPjXr+KwPDDSopyf9C6cC2jvFXGNU/dtcpTYjsqYUudD07/YaN8iXP/onEj5DRA1hN8ASvsFqfaDaMYRlj99l+IWf1v8z8P7y4mUfixs8+entZG2h5L2Ntq3A31PISdsFv0DTZvH2nsrLUj7tef/u38OLy0AAAAAAAAAAAAAAMw+8MEOAAAAAAAAAAAAAIAeomOTWG4O03ZUkJ0ANOXsfGmc2OcG03Fm3srNB53T2fz4Nz+u6h6TzE9mBUnz2XFDzUTSSu8cd88pR+MNr7/hprP2MUfLpJMdcW87diuYy7rHJvkR37iYJXLNZHifpKy+rjlCc4iZiBazBg2azjFO9jdvd9O0O98y541ZGuf0J29rfizYPeLO689NTN12MSF7ltsHDdY/rB7Nmj3ca42scQo51kHu0X/+N6++1qdWYTu8DwAAAAAAAAAAAIBwwg4AAAAAAAAAAAAAgJ4CH+wAAAAAAAAAAAAAAOghOjaJjfszO77EMTnlZpcBUwwMXTPLwH/tKrJa5p28hI5JbGGCla+UZVgdsW0VualmjinXukqP3Gy1TYVVUl51zB25iWzUlE1ipfy4qScRETFT0MAynbVv4/lzhZqkbOdn5dHozDaTm5hqz1XzYKavXHHXVdOx1HhZ+2lqt+74serI4nLb7eFeaWbKgRU+Hmv2w6IqN7ElER7HlWBd1TtNyWi2YoSVJFWUxYJEUWCS0ihtl6vI+QWpP05TUpKU3ojscdoWJyhEqQp77rxnpEJjcBP5tjR+0bYd5RDmbG6LrHymj3t/OTRFrLygpEukKOkp7aepUeUVJdCxwK8cmJ+QZaA0hWBVyXaWIypBE1FSFsa8otCZU8Z8N+0YKfNfHKPaPFZUx6Q5TqSrM0p0M/81pTJN0S0SFNOCWN4Oau/5SFDt01yMaG0r9r2ygErr+45nyXGuInwrP0H5mkgf03Px3c7R5qWkBqupxKpK8aLsrJxGVXWd8oeraqXKGNYUX6X1QVWDV/cHM0+jvRNLW/wZpuP++UBEqisXaX3oRklTy8/d69uJ5PyKo4qKvPHvAdKCkp+qVusPngvqsWr7SyjzVX2HCc2v/KSgQJERlea5tp5re1hJyZhIbqdQUYLW5rI0prT+0MpX3ObPMKwrn4SU8Sutk9raqu0ppPeMIgRNpOwp8hPKXjOZuXqwFifO813gCmsOLCEAAAAAAAAAAAAAAMwd8MEOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoITr3YVfOrpuDiu028/+Vn5SNdi1Tcyc7y4ed4v+CmH00t+WOpuzvkCZn2H2dlUnzN2CV3c1OqZd0n+W/pi0/v/+4wLGFt2y+WQFd/zdxX3aj6c8MsaOSbZSdsnZKxjKHWDnH/w33G8b9EbiuBELmC4D7dNNs8NM8y9vNj/kCcX2hcfty7rvIhI6/vCp3HsieW3R9zvnb03WZwcvI/XOofksAAAAAAAAAAAAAHHDCDgAAAAAAAAAAAACAHgIf7AAAAAAAAAAAAAAA6CECYwzs9QAAAAAAAAAAAAAA6BFwwg4AAAAAAAAAAAAAgB4CH+wAAAAAAAAAAAAAAOgh8MEOAAAAAAAAAAAAAIAeAh/sAAAAAAAAAAAAAADoIfDBDgAAAAAAAAAAAACAHgIf7AAAAAAAAAAAAAAA6CHwwQ4AAAAAAAAAAAAAgB4CH+wAAAAAAAAAAAAAAOgh8MEOAAAAAAAAAAAAAIAe4v8HPR1OLqeS8CYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1600x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Assuming WL_tensor is a 4D tensor with shape (num_images, height, width, channels)\n",
        "# and sub_image_size is the size of the second and third dimensions (height and width).\n",
        "num_images = 5\n",
        "sub_image_size = WL_tensor.shape[1]  # Assuming height and width are the same\n",
        "\n",
        "[vmin, vmax]=[-0.05, .1];\n",
        "[vmin2, vmax2]=[-0.05, .1];\n",
        "\n",
        "print(vmin2)\n",
        "\n",
        "show_difference = False\n",
        "make_last_image_zoom = True\n",
        "number_decoders = 4\n",
        "\n",
        "decoded_images = [None]*num_images\n",
        "\n",
        "# Get the outputs from the decoder\n",
        "decoded_images[0] = simple_decoder(simple_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "if number_decoders >= 2:\n",
        "  decoded_images[1] = CNN_decoder(CNN_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=3:\n",
        "    decoded_images[2] = decoder_residconnect(encoder_residconnect(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=4:\n",
        "    #decoded_images[3] = zoom(WL_tensor[index, :, :, 0], 0.25)\n",
        "    decoded_images[3] = decoder(encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "# Function to display images\n",
        "def display_side_by_side(index):\n",
        "    if index < 0 or index >= num_images:\n",
        "        raise ValueError(\"Index out of bounds\")\n",
        "\n",
        "    # Select the specific input and output images\n",
        "    input_image = WL_tensor[index, :, :, 0]  # Assuming grayscale, channel dimension is 0\n",
        "\n",
        "    if make_last_image_zoom:\n",
        "      decoded_images[-1] = zoom(np.array(input_image).astype(np.float32), 0.25)\n",
        "      decoded_images_comparison = np.array(zoom(decoded_images[-1], 4)).astype(np.float16)\n",
        "      print(\"MAE loss for averaged map = \", np.mean(np.abs(input_image -decoded_images_comparison)))\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, axes = plt.subplots(1, number_decoders+1, figsize=(4*number_decoders, 10))\n",
        "\n",
        "    # Display the input image in the first subplot\n",
        "    axes[0].imshow(input_image, cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "    axes[0].set_title(f'Input Image {index}')\n",
        "    axes[0].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the output image in the second subplot\n",
        "    for i in range(number_decoders):\n",
        "        output_image = decoded_images[i][index, :, :, 0]\n",
        "\n",
        "        print(f\"MAE loss for decoder {i} = \", np.mean(np.abs(input_image -output_image )))\n",
        "        if show_difference:\n",
        "          vmin2 = -.02; vmax2=0.02\n",
        "          output_image = output_image - input_image\n",
        "        axes[i+1].imshow(output_image, cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "        axes[i+1].set_title(f'Decoded Image {i}, {index}')\n",
        "        axes[i+1].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the images\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage for the first image\n",
        "display_side_by_side(0)  # You can loop or call this function for other indices as well\n",
        "display_side_by_side(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GZVUaQrSvDm"
      },
      "id": "0GZVUaQrSvDm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWlZQW_4SsXN"
      },
      "id": "mWlZQW_4SsXN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIzHnYPxSqq8"
      },
      "id": "xIzHnYPxSqq8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e8d6bc",
      "metadata": {
        "id": "97e8d6bc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}