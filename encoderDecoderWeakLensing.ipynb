{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed531a95",
      "metadata": {
        "id": "ed531a95"
      },
      "source": [
        "#Implements encoder/decoder for weak lensing outputs\n",
        "\n",
        "The major idea is to see if I can compress the data in the snapshot files.\n",
        "The result is that the compression of many different algorithms based on CNNs (of different depths) is not so much different than averaging neighboring cells.  This in retrospect is not so surprising as there are differences on the cell scale in the maps that make compression challenging."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set configurations for COLAB if running there"
      ],
      "metadata": {
        "id": "zQpe_fjWxGwO"
      },
      "id": "zQpe_fjWxGwO"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "use_COLAB = 1\n",
        "\n",
        "if use_COLAB == 1:\n",
        "  #mount drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  WORK_AREA = '/content/gdrive/My Drive/weaklensing_ML/' #columbialensing/\n",
        "  os.chdir(WORK_AREA)\n",
        "\n",
        "  #get GPU info\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEtElnI8fDj1",
        "outputId": "a7eb12cc-d17a-40be-832e-fc7162bc3b04"
      },
      "id": "KEtElnI8fDj1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Thu Nov 16 18:14:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## extract tarfiles if necessary and set specs for run\n",
        "\n"
      ],
      "metadata": {
        "id": "MSxBOjESwy_q"
      },
      "id": "MSxBOjESwy_q"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4a5315a",
      "metadata": {
        "id": "a4a5315a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tarfile\n",
        "import os\n",
        "import shutil\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "#whether we are training or loading saved\n",
        "train = True\n",
        "load_saved = 1\n",
        "L1weight = 0 #1e-8\n",
        "dropout_rate = 0\n",
        "\n",
        "# Specify the directory containing the .tar files\n",
        "directory_path = './columbialensing/'\n",
        "\n",
        "\n",
        "max_cosmologies = -1 #for testing.  Set to -1 to use everything.\n",
        "\n",
        "number_batches = 10\n",
        "#validation_split = 0.4  # use this fraction of the data for validation\n",
        "normalize_by_RMS = False #set to one if you want to renormalize by RMS\n",
        "\n",
        "\n",
        "\n",
        "# image_size\n",
        "image_size = 1024 #really makes sense to use the 1024s\n",
        "sub_image_size = 64 #needs to divide image size\n",
        "\n",
        "\n",
        "\n",
        "number_subimages_across =image_size//sub_image_size\n",
        "\n",
        "\n",
        "number_fits_files = 512\n",
        "suffix = f\"_{image_size}\"\n",
        "extract_tarfiles = False  #if I need to extract tarfiles\n",
        "\n",
        "run_suffix = rf\"im{image_size}\"\n",
        "\n",
        "#extracts only if indicated (could make this more elegant by checking to see if they exist)\n",
        "if extract_tarfiles:\n",
        "    # Use a regular expression to match .tar files with the desired suffix\n",
        "    pattern = re.compile(rf\"{suffix}.tar$\")\n",
        "\n",
        "    # List all matching .tar files in the directory\n",
        "    all_tar_files = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "\n",
        "    # Extract the tar archive\n",
        "    for tar_file in all_tar_files:\n",
        "        #print(tar_file)\n",
        "        tar_file_path = os.path.join(directory_path, tar_file)\n",
        "        with tarfile.open(tar_file_path, 'r') as archive:\n",
        "            archive.extractall(path=directory_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training schedule and import optimizer"
      ],
      "metadata": {
        "id": "hikn1ojDWiGH"
      },
      "id": "hikn1ojDWiGH"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "#I was curious about how much of the loss owed to regularization, so this allows me to check at end of each batch (but was generating a warning in first batch)\n",
        "class RegularizationLossMonitor(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        regularization_loss = sum(self.model.losses)\n",
        "        total_loss = logs['loss']\n",
        "        data_loss = total_loss - regularization_loss\n",
        "        print(f'\\n Regularization loss: {regularization_loss:.4f}',)\n",
        "        print(f'Data loss: {data_loss:.4f}',)\n",
        "        print(f'Total loss: {total_loss:.4f}')\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.0001)"
      ],
      "metadata": {
        "id": "3i4uiA3rWg_n"
      },
      "id": "3i4uiA3rWg_n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0619681f",
      "metadata": {
        "id": "0619681f"
      },
      "source": [
        "# Read into memory the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "48a05090",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48a05090",
        "outputId": "a8b24ce9-f8d8-4ff1-b10a-fb8f0805866d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading in Om0.268_si0.801\n",
            "RMS=0.016497720032930374\n"
          ]
        }
      ],
      "source": [
        "def get_labels_for_file(dir_name):\n",
        "    \"\"\"\n",
        "    Extracts labels from the tar file name.\n",
        "    For the file \"Om0.183_si0.958_256.tar\", the labels will be [0.183, 0.958].\n",
        "\n",
        "    Args:\n",
        "    - tar_file_name (str): Name of the tar file.\n",
        "\n",
        "    Returns:\n",
        "    - list: List containing the two labels extracted from the filename.\n",
        "    \"\"\"\n",
        "    # Split the filename on underscores\n",
        "    parts = dir_name.split('_')\n",
        "\n",
        "    # Extract the numeric values for 'Om' and 'si'\n",
        "    om_label = float(parts[0][2:])\n",
        "    si_label = float(parts[1][2:])\n",
        "\n",
        "    return [om_label, si_label]\n",
        "\n",
        "\n",
        "#now loop through all files in the\n",
        "pattern = re.compile(rf\"{suffix}$\")\n",
        "#all_directories = [f for f in os.listdir(directory_path) if pattern.search(f)]\n",
        "all_directories = [\"Om0.268_si0.801\"] # \"Om0.283_si0.805_256\"\n",
        "num_cosmologies = len(all_directories)\n",
        "\n",
        "random.shuffle(all_directories) #this makes it so that there is no particular order for the directories\n",
        "#print(all_directories)\n",
        "\n",
        "#tensor of labels; there are two labels for each\n",
        "numsubimages = number_subimages_across**2\n",
        "number_images = number_fits_files*numsubimages\n",
        "#cosmology_labels = np.empty((len(all_directories), number_images, 2), dtype=np.float16)\n",
        "\n",
        "RMS =0 #first time set to zero\n",
        "data_array = np.empty((num_cosmologies, number_images, sub_image_size, sub_image_size), dtype=np.float16)\n",
        "for idy, dir_name in enumerate(all_directories):\n",
        "    if max_cosmologies>0 and idy >= max_cosmologies:\n",
        "        break\n",
        "\n",
        "    #if idy%10 ==0:\n",
        "    print(\"reading in\", dir_name)\n",
        "    dir_path = os.path.join(directory_path, dir_name)\n",
        "\n",
        "    all_files = os.listdir(dir_path)\n",
        "    fits_files = [f for f in all_files if f.endswith('.fits')]\n",
        "\n",
        "\n",
        "\n",
        "    for idx, file in enumerate(fits_files):\n",
        "        with fits.open(os.path.join(dir_path, file)) as hdul:\n",
        "\n",
        "            original_data = hdul[0].data\n",
        "\n",
        "            if RMS == 0: #get RMS to divide by for first file to normalize everything\n",
        "                RMS = np.sqrt(np.var(hdul[0].data))\n",
        "                print(f\"RMS={RMS}\")\n",
        "\n",
        "            ##get rid of NANs, which affects a few files\n",
        "            #if np.isnan(original_data).any():\n",
        "            #    continue\n",
        "            #I've cleaned this out already\n",
        "            for i in range(number_subimages_across):\n",
        "                for j in range(number_subimages_across):\n",
        "                    data_array[idy][numsubimages*idx+ number_subimages_across*i+j] = original_data[sub_image_size*i:sub_image_size*(i+1),\\\n",
        "                                                                  sub_image_size*j:sub_image_size*(j+1)]\n",
        "\n",
        "    #since all fits files in one directory have the same label\n",
        "    cosmology = get_labels_for_file(dir_name)\n",
        "    #cosmology_labels[idy] = np.array([cosmology for i in range(number_fits_files)])\n",
        "\n",
        "\n",
        "    #flatten data_array[idy][numsubimages*idx+ number_subimages_across*i+j]\n",
        "WL_tensor = tf.convert_to_tensor(data_array)\n",
        "\n",
        "WL_tensor = tf.reshape(WL_tensor, (-1, WL_tensor.shape[2], WL_tensor.shape[3]));\n",
        "\n",
        "WL_tensor = WL_tensor[..., np.newaxis]  # Add channel dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621149d6",
      "metadata": {
        "id": "621149d6"
      },
      "source": [
        "# create decoder-encoder CNN with minimal number of layers, but final dense layer.  \n",
        "\n",
        "  Here n sets the compression with the size compressed by the factor 4^n.  The result is n+1 layers, and most experiments I've run to test are n=2, or a compression by a factor of 16.\n",
        "\n",
        "  The n CNN layers have number_channels channels, where I've experimented with 64 and 256\n",
        "\n",
        "If load_saved= 1, it loads a trained version of this decoder-encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828293a3",
      "metadata": {
        "id": "828293a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03a89da-123e-473b-cd5b-875ab109f673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path does not exist to simple_encoder_n2_nc64_d0_logL1w+00.keras.  Creating model\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=2 #number of layers (needs to be >2)\n",
        "number_channels = 64\n",
        "\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_simple_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_string, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "              kernel_regularizer=regularizer))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_simple_decoder(encoded_length, original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    model.add(layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string,\\\n",
        "              kernel_regularizer=regularizer))\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_string, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "\n",
        "model_name = f'simple_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    simple_encoder = load_model(model_name)\n",
        "    simple_decoder = load_model(f'simple_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  simple_encoder = create_simple_encoder(original_shape , n)\n",
        "  simple_decoder = create_simple_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "simple_autoencoder = models.Sequential([simple_encoder, simple_decoder])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff71209a",
      "metadata": {
        "id": "ff71209a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d5c9de-db2d-401a-8373-24a09c753a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               4194560   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4213632 (16.07 MB)\n",
            "Trainable params: 4213504 (16.07 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16384)             4210688   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 16, 16, 64)        36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSamplin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4266369 (16.27 MB)\n",
            "Trainable params: 4266241 (16.27 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "simple_encoder.summary() #summary of encoder\n",
        "simple_decoder.summary() #summary of decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sets a learning rate scheduler, compiles the model, and trains\n",
        "\n",
        "I've experimented with larger learning rates than 0.001, finding that five times this is too high as loss is very non-monatonic"
      ],
      "metadata": {
        "id": "Ex2CN7yS1nje"
      },
      "id": "Ex2CN7yS1nje"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6a8f7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6a8f7c",
        "outputId": "7bfd28cd-957f-4229-bb5c-f3309d5dc587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 32s 59ms/step - loss: 0.0075 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0052 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0045 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0042 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0041 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0040 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0039 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 30s 58ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0043 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0038 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0037 - lr: 5.0000e-04\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 30s 59ms/step - loss: 0.0037 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "if train:\n",
        "  # Set the learning rate (I find that .005 is too large)\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  simple_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "\n",
        "  simple_autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch\n",
        "  simple_encoder.save(f'simple_encoder_{save_string}.keras')\n",
        "  simple_decoder.save(f'simple_decoder_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder-decoder 2:  \n",
        "\n",
        "This takes out the dense layers and replaces it with 1x1 convolution layer.  This makes a pure CNN encoder-decoder and the output now is in terms of pixels and channels rather than one vector.  This felt more physically motivated.  Now n=4 and 16 channels is the same compression as n=2 previously."
      ],
      "metadata": {
        "id": "7rHxc33vp9W3"
      },
      "id": "7rHxc33vp9W3"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "#Parameters for network\n",
        "n=4 #number of layers (needs to be >2)\n",
        "number_channels = 256 #these are intermediate  channels\n",
        "number_final_channels = 16  # if n=4 and number_final_channels = 16, this is eqivalent to n=2 decompression in other encoders\n",
        "\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_nfc{number_final_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "def create_CNN_encoder(input_shape, n,  number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=None, padding='same',\\\n",
        "              kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "\n",
        "    model.add(layers.Conv2D(number_final_channels, (1, 1), activation=None, padding='same',\\\n",
        "          kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "\n",
        "    #model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, \\\n",
        "    #          kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_CNN_decoder(original_shape, n, number_channels=number_channels, dropout_rate=dropout_rate):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer( (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_final_channels)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same',\\\n",
        "                  kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Activation(act_string))\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "        if dropout_rate >0:\n",
        "          model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=None, padding='same',\\\n",
        "                                     kernel_regularizer=regularizer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Activation(act_string))\n",
        "\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "    if dropout_rate >0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same',\\\n",
        "      kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "model_name = f'CNN_encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    CNN_encoder = load_model(model_name)\n",
        "    CNN_decoder = load_model(f'CNN_decoder_{save_string}.keras')\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "      print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  CNN_encoder = create_CNN_encoder(original_shape, n)\n",
        "  CNN_decoder = create_CNN_decoder(original_shape, n)\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "CNN_autoencoder = models.Sequential([CNN_encoder, CNN_decoder])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658b8wytptj2",
        "outputId": "ce930bd3-d98f-4741-f113-0c2399855a76"
      },
      "id": "658b8wytptj2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path does not exist to CNN_encoder_n4_nc256_nfc16_d0_logL1w+00.keras.  Creating model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_encoder.summary()\n",
        "CNN_decoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiALX9LEp7FV",
        "outputId": "cf4040a4-bd68-459e-d960-22688018bb94"
      },
      "id": "PiALX9LEp7FV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 128)       1280      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 4, 4, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 16)          4112      \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 4, 4, 16)          64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1484368 (5.66 MB)\n",
            "Trainable params: 1482544 (5.66 MB)\n",
            "Non-trainable params: 1824 (7.12 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_transpose_4 (Conv2D  (None, 4, 4, 256)         4352      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 4, 4, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2D  (None, 4, 4, 256)         590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 4, 4, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " up_sampling2d_4 (UpSamplin  (None, 8, 8, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2D  (None, 8, 8, 256)         590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " up_sampling2d_5 (UpSamplin  (None, 16, 16, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2D  (None, 16, 16, 256)       590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " up_sampling2d_6 (UpSamplin  (None, 32, 32, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2D  (None, 32, 32, 128)       295040    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " up_sampling2d_7 (UpSamplin  (None, 64, 64, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 64, 64, 1)         129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2074369 (7.91 MB)\n",
            "Trainable params: 2072065 (7.90 MB)\n",
            "Non-trainable params: 2304 (9.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train:\n",
        "\n",
        "  learning_rate = .001\n",
        "\n",
        "  CNN_autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")\n",
        "  CNN_autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()  If inlclude RegularizationLossMonitor() as a callback, separately prints regularization loss at the end of each batch\n",
        "  CNN_encoder.save(f'CNN_encoder_{save_string}.keras')\n",
        "  CNN_decoder.save(f'CNN_decoder_{save_string}.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0geI0hW3WnE",
        "outputId": "4e711990-1ec7-42a5-d66f-c7cc11599151"
      },
      "id": "Y0geI0hW3WnE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "512/512 [==============================] - 169s 311ms/step - loss: 0.0181 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0075 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0071 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0066 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0065 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0063 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0060 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0057 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0055 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0053 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0052 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0051 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0051 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0049 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0052 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0047 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "512/512 [==============================] - 159s 311ms/step - loss: 0.0046 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "512/512 [==============================] - 160s 312ms/step - loss: 0.0046 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OueELMBd7HuO"
      },
      "id": "OueELMBd7HuO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder Decoder 3 (residual connections)\n",
        "\n",
        "This now is the same CNN as our first but with residual connections"
      ],
      "metadata": {
        "id": "ifU_ceKxiGtH"
      },
      "id": "ifU_ceKxiGtH"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KbAkbrpXiMrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c0cc3c-2a47-47bc-9020-762cda222af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None, 64, 64, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 64)           640       ['input_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 64, 64, 64)           256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 32, 32, 64)           0         ['activation_16[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 64)           36928     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 32, 32, 64)           256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 32, 32, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 32, 32, 64)           256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 32, 32, 64)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 32, 32, 64)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 16, 16, 64)           0         ['activation_18[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 16384)                0         ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  4194560   ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4269824 (16.29 MB)\n",
            "Trainable params: 4269440 (16.29 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)       [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 16384)                4210688   ['input_10[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)         (None, 16, 16, 64)           0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 16, 16, 64)           256       ['reshape_3[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_12 (Conv2  (None, 16, 16, 64)           36928     ['activation_19[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_12[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_13 (Conv2  (None, 16, 16, 64)           36928     ['activation_20[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_13[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 64)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 16, 16, 64)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampli  (None, 32, 32, 64)           0         ['activation_21[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_14 (Conv2  (None, 32, 32, 64)           36928     ['up_sampling2d_10[0][0]']    \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampli  (None, 64, 64, 64)           0         ['conv2d_transpose_14[0][0]'] \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 64, 64, 1)            65        ['up_sampling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4322305 (16.49 MB)\n",
            "Trainable params: 4321921 (16.49 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
        "\n",
        "n=2\n",
        "number_channels = 64\n",
        "\n",
        "act_string = LeakyReLU(alpha=0.1) #okay, not a string\n",
        "\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "\n",
        "def create_encoder_residconnect(input_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Initial Convolutional Layer\n",
        "    x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Additional Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2D(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Flatten and Dense Layer\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "def create_decoder_residconnect(encoded_length, original_shape, n, number_channels=number_channels, act_string=act_string, dropout_rate=0, regularizer=regularizer):\n",
        "    inputs = layers.Input(shape=(encoded_length,))\n",
        "    x = inputs\n",
        "\n",
        "    # Dense layer\n",
        "    x = layers.Dense(units=np.prod(encoded_length*number_channels), activation=act_string, kernel_regularizer=regularizer)(x)\n",
        "    x = layers.Reshape((original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), number_channels))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(act_string)(x)\n",
        "\n",
        "    # Upsampling Layers with Residual Connections\n",
        "    for _ in range(1, n):\n",
        "        identity = x\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.Conv2DTranspose(number_channels, (3, 3), activation=None, padding='same', kernel_regularizer=regularizer)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Add()([x, identity])  # Residual Connection\n",
        "        x = layers.Activation(act_string)(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        if dropout_rate > 0:\n",
        "            x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Final Conv2DTranspose to get back to original shape\n",
        "    x = layers.Conv2DTranspose(number_channels, (3, 3), activation=act_string, padding='same', kernel_regularizer=regularizer)(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    if dropout_rate > 0:\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "model_name = f'encoder_residconnect_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    encoder_residconnect= load_model(f'encoder_residconnect_{save_string}.keras')\n",
        "    decoder_residconnect = load_model(f'decoder_residconnect_{save_string}.keras')\n",
        "\n",
        "else:\n",
        "  if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model\")\n",
        "  encoder_residconnect = create_encoder_residconnect(original_shape , n)\n",
        "  decoder_residconnect = create_decoder_residconnect(encoded_length,original_shape, n)\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "autoencoder_residconnect = models.Sequential([encoder_residconnect, decoder_residconnect])\n",
        "\n",
        "encoder_residconnect.summary()\n",
        "decoder_residconnect.summary()"
      ],
      "id": "KbAkbrpXiMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Combine the encoder and decoder to create the autoencoder\n",
        "autoencoder_residconnect = models.Sequential([encoder_residconnect, decoder_residconnect])\n",
        "#autoencoder_residconnect.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "zJb9DKNqizkS"
      },
      "id": "zJb9DKNqizkS",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train:\n",
        "  # Set the learning rate\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  autoencoder_residconnect.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mae\")\n",
        "\n",
        "  autoencoder_residconnect.fit(WL_tensor, WL_tensor, epochs=20,batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr]) #, RegularizationLossMonitor()\n",
        "  encoder_residconnect.save(f'encoder_residconnect_{save_string}.keras')\n",
        "  decoder_residconnect.save(f'decoder_residconnect_{save_string}.keras')"
      ],
      "metadata": {
        "id": "qTDG33XFy2Ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cdfaef-4a8f-4803-c156-07672c4e3ad3"
      },
      "id": "qTDG33XFy2Ec",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "261/512 [==============>...............] - ETA: 28s - loss: 0.0053"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95cc9323",
      "metadata": {
        "id": "95cc9323"
      },
      "source": [
        "## Encoder-decoder 4: most complex model\n",
        "\n",
        "I've added 2*(n-1) additional layers, half 1x1 convolutions and half 3x3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82c7819",
      "metadata": {
        "id": "b82c7819"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "n=2\n",
        "number_channels = 64\n",
        "\n",
        "act_func = LeakyReLU(alpha=0.1)\n",
        "\n",
        "\n",
        "# Conditionally add L1 regularizer if L1weight is greater than 0\n",
        "if L1weight > 0:\n",
        "    regularizer = regularizers.l1(L1weight)\n",
        "else:\n",
        "    regularizer = None\n",
        "\n",
        "\n",
        "#string with parameters for saving\n",
        "sci_notation = \"{:.0e}\".format(L1weight)\n",
        "exponent = sci_notation.split('e')[-1]\n",
        "save_string = f'n{n}_nc{number_channels}_d{dropout_rate }_logL1w{exponent}'\n",
        "\n",
        "\n",
        "def create_encoder(input_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    if n<2:\n",
        "        print(\"n is too small.  n >=2\")\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape))\n",
        "\n",
        "    model.add(layers.Conv2D(number_channels//2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    for nlayer in range(1,n):\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2D(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2D(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Adding a Dense layer for encoding\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=(input_shape[0] * input_shape[1]) // (4 ** n), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_decoder(encoded_length, original_shape, n, number_channels=64, act_string=act_string, regularizer=regularizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input is a flat array\n",
        "    model.add(layers.InputLayer((encoded_length,)))\n",
        "\n",
        "\n",
        "\n",
        "    # Expanding the flat array to a 3D tensor\n",
        "    model.add(layers.Dense(units=np.prod(encoded_length*64), activation=act_func, kernel_regularizer=regularizer))\n",
        "\n",
        "\n",
        "    # Calculate the dimensions for the first reshape\n",
        "    # It should match the output size of the last MaxPooling layer in the encoder\n",
        "    reshape_dims = (original_shape[0] // (2 ** n), original_shape[1] // (2 ** n), 64)\n",
        "\n",
        "    model.add(layers.Reshape(reshape_dims))\n",
        "\n",
        "    # Upsampling to original size, looping over number of layers\n",
        "    for nlayer in range(1, n):\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "        model.add(layers.Conv2DTranspose(number_channels, (3, 3), activation=act_func, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(number_channels, (1, 1), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2DTranspose(number_channels/2, (3, 3), activation=act_func, padding='same', kernel_regularizer=regularizer))\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    # Final layer to reconstruct the image\n",
        "    model.add(layers.Conv2D(original_shape[2], (1, 1), activation='linear', padding='same', kernel_regularizer=regularizer))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n=2 #number of layers (needs to be >2)\n",
        "original_shape = [sub_image_size, sub_image_size, 1]\n",
        "\n",
        "\n",
        "encoded_length = sub_image_size*sub_image_size//int(4**n)\n",
        "\n",
        "#load_saved = 1\n",
        "model_name = f'encoder_{save_string}.keras'\n",
        "if load_saved == 1 and os.path.exists(model_name):\n",
        "    encoder= load_model(f'encoder_{save_string}.keras')\n",
        "    decoder = load_model(f'decoder_{save_string}.keras')\n",
        "else:\n",
        "    if load_saved == 1 and not os.path.exists(model_name):\n",
        "        print(f\"Path does not exist to {model_name}.  Creating model...\")\n",
        "    # Combine the encoder and decoder to create the autoencoder\n",
        "    encoder = create_encoder(original_shape , n)\n",
        "    decoder = create_decoder(encoded_length,original_shape, n)\n",
        "\n",
        "autoencoder = models.Sequential([encoder, decoder])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de30dd6",
      "metadata": {
        "id": "0de30dd6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an Adam optimizer with the desired learning rate\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "def fractional_difference_loss(y_true, y_pred):\n",
        "    # Avoid division by zero\n",
        "    epsilon = .01 # A small, non-zero number to prevent division by zero\n",
        "    # Calculate the fractional difference\n",
        "    loss = K.mean(K.abs((y_pred - y_true) / (K.abs(y_true) + epsilon)), axis=-1)\n",
        "    return loss\n",
        "\n",
        "def fractional_square_loss(y_true, y_pred):\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-2 # A small, non-zero number to prevent division by zero\n",
        "    # Calculate the fractional difference\n",
        "    loss = K.square((y_pred - y_true) / (K.abs(y_true) + epsilon))\n",
        "    return loss\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0659942d",
      "metadata": {
        "id": "0659942d"
      },
      "source": [
        "# compile and train complex CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da431d7",
      "metadata": {
        "id": "7da431d7"
      },
      "outputs": [],
      "source": [
        "if train:\n",
        "  # Set the learning rate\n",
        "  learning_rate = 0.001\n",
        "  autoencoder.compile(optimizer==Adam(learning_rate=learning_rate), loss=\"mae\") #loss=fractional_difference_loss) #, run_eagerly=True)\n",
        "  autoencoder.fit(WL_tensor, WL_tensor, epochs=20, batch_size=256,\n",
        "                shuffle=True, callbacks=[reduce_lr])\n",
        "  encoder.save(f'encoder_{save_string}.keras')\n",
        "  decoder.save(f'decoder_{save_string}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This shows images from the various encoders/decoders\n",
        "\n",
        "change number_dcoders to compare more decoders, if they are loaded\n"
      ],
      "metadata": {
        "id": "FndU2Dzi3GSJ"
      },
      "id": "FndU2Dzi3GSJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca90b78c",
      "metadata": {
        "id": "ca90b78c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming WL_tensor is a 4D tensor with shape (num_images, height, width, channels)\n",
        "# and sub_image_size is the size of the second and third dimensions (height and width).\n",
        "num_images = 5\n",
        "sub_image_size = WL_tensor.shape[1]  # Assuming height and width are the same\n",
        "\n",
        "number_decoders = 1\n",
        "\n",
        "# Get the outputs from the decoder\n",
        "decoded_images1 = simple_decoder(simple_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "if number_decoders >= 2:\n",
        "  decoded_images2 = CNN_decoder(CNN_encoder(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=3:\n",
        "    decoded_images3 = decoder_residconnect(encoder_residconnect(WL_tensor[:num_images,...])).numpy()\n",
        "if number_decoders >=4:\n",
        "    decoded_images4 = decoder(encoder(WL_tensor[:num_images,...])).numpy()\n",
        "\n",
        "# Function to display images\n",
        "def display_side_by_side(index):\n",
        "    if index < 0 or index >= num_images:\n",
        "        raise ValueError(\"Index out of bounds\")\n",
        "\n",
        "    # Select the specific input and output images\n",
        "    input_image = WL_tensor[index, :, :, 0]  # Assuming grayscale, channel dimension is 0\n",
        "    output_image1 = decoded_images1[index, :, :, 0]  # Also assuming grayscale\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, axes = plt.subplots(1, number_decoders+1, figsize=(4*number_decoders, 10))\n",
        "\n",
        "    # Display the input image in the first subplot\n",
        "    axes[0].imshow(input_image, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "    axes[0].set_title(f'Input Image {index}')\n",
        "    axes[0].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the output image in the second subplot\n",
        "    axes[1].imshow(output_image1, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "    axes[1].set_title(f'Decoded Image {index}')\n",
        "    axes[1].axis('off')  # Hide the axis\n",
        "\n",
        "    if number_decoders >=2:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image2 = decoded_images2[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[2].imshow(output_image2, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[2].set_title(f'Decoded 2 Image {index}')\n",
        "      axes[2].axis('off')  # Hide the axis\n",
        "\n",
        "    if number_decoders >=3:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image3 = decoded_images3[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[3].imshow(output_image3, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[3].set_title(f'Decoded 3 Image {index}')\n",
        "      axes[3].axis('off')  # Hide the axis\n",
        "\n",
        "\n",
        "    if number_decoders >=4:\n",
        "      # Display the output image in the second subplot\n",
        "      output_image4 = decoded_images4[index, :, :, 0]  # Also assuming grayscale\n",
        "      axes[3].imshow(output_image4, cmap='viridis', vmin=-0.05, vmax=.1)\n",
        "      axes[3].set_title(f'Decoded 4 Image {index}')\n",
        "      axes[3].axis('off')  # Hide the axis\n",
        "\n",
        "    # Display the images\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage for the first image\n",
        "display_side_by_side(0)  # You can loop or call this function for other indices as well\n",
        "display_side_by_side(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e8d6bc",
      "metadata": {
        "id": "97e8d6bc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}